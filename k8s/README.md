# K8sæ‰‹åŠ¨å®‰è£…è¿‡ç¨‹
+++
title= "ğŸ“’ K8sç¬”è®°äºŒ.  - æ­å»ºK8sç¯å¢ƒ"
url= "/posts/k8sea795d75f38c02/"
aliases = ["/posts/k8s003"]
description= "Kubernetes æ˜¯ç”¨äºè‡ªåŠ¨éƒ¨ç½²,æ‰©å±•å’Œç®¡ç†å®¹å™¨åŒ–åº”ç”¨ç¨‹åºçš„å¼€æºç³»ç»Ÿã€‚ å®ƒå°†ç»„æˆåº”ç”¨ç¨‹åºçš„å®¹å™¨ç»„åˆæˆé€»è¾‘å•å…ƒ,ä»¥ä¾¿äºç®¡ç†å’ŒæœåŠ¡å‘ç°ã€‚"
image= "/img/res/blog.jpg"
date= 2020-06-27T08:22:31+08:00
lastmod= 2020-06-27T08:22:31+08:00
categories= ["K8s"]
tags= ["K8s"]
archives= "2020"
author= "å²å¸ƒæ–¯"
height= 1587401551
draft= false

+++

[TOC]






## æ‰‹åŠ¨å®‰è£…

###  1. å‡†å¤‡å·¥ä½œ

| ç³»ç»Ÿç±»å‹ | IPåœ°å€    | èŠ‚ç‚¹è§’è‰² | CPU  | Memory | Hostname |
| -------- | --------- | -------- | ---- | ------ | -------- |
| Centos7  | 10.0.0.11 | master   | 1    | 2G     | s001.k8s.com |
| Centos7  | 10.0.0.12 | worker   | 1    | 2G     | s002.k8s.com |
| Centos7  | 10.0.0.13 | worker   | 1    | 2G     | s003.k8s.com |

-   **1.1 å…³é—­é˜²ç«å¢™**

```bash
systemctl stop firewalld
systemctl disable firewalld
firewall-cmd --state
```

-   **1.2 é…ç½®hosts**

```bash
cat <<EOF >> /etc/hosts
10.0.0.11 s001.k8s.com
10.0.0.12 s002.k8s.com
10.0.0.13 s003.k8s.com
EOF
```

-   **1.3 è®¾ç½®ç³»ç»Ÿå‚æ•°**

```bash
cat <<EOF > /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
 
#ç”Ÿæ•ˆé…ç½®æ–‡ä»¶
sysctl -p /etc/sysctl.d/k8s.conf
```

-   **1.4 è®¾ç½®ç¯å¢ƒå˜é‡**

```bash
cat <<EOF > ~/.bash_profile
	export K8S_IP=10.0.0.11
	export K8S_ROLE=MASTER æˆ– WORKER	#æœåŠ¡å™¨è§’è‰²
EOF
```

-   **1.5 å‡†å¤‡K8sç»„ä»¶**

>   å®˜æ–¹ä¸‹è½½:[å‚è€ƒåœ°å€ä¸€](https://github.com/kubernetes/kubernetes/blob/master/staging/README.md) æˆ– [å‚è€ƒåœ°å€äºŒ](https://www.downloadkubernetes.com)  ã€€ã€€ã€€ã€€ã€€
>
>   ç™¾åº¦ç½‘ç›˜ï¼šhttps://pan.baidu.com/s/19nG82wks5A4w7VJ0uqk-HA æå–ç : pci7

_æ‰€éœ€ç»„ä»¶å¦‚ä¸‹ï¼š_

```bash
[root@vm k8s]# tree
â”œâ”€â”€ calico
â”œâ”€â”€ calicoctl
â”œâ”€â”€ calico-ipam
â”œâ”€â”€ etcd
â”œâ”€â”€ etcdctl
â”œâ”€â”€ kube-apiserver
â”œâ”€â”€ kube-controller-manager
â”œâ”€â”€ kubectl
â”œâ”€â”€ kubelet
â”œâ”€â”€ kube-proxy
â”œâ”€â”€ kube-scheduler
â”œâ”€â”€ loopback
â””â”€â”€ VERSION.md
```



### 2. å®‰è£…Docker(All)

```bash
VERSION=docker-ce-18.06.1.ce-3.el7.x86_64.rpm
wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/${VERSION}
yum install -y ./${VERSION}

systemctl enable docker
systemctl start docker
docker version

# docker run hello-world
```



### 3. å®‰è£…Etcd(Master)

```shell
cp target/master-node/etcd.service /lib/systemd/system/
systemctl enable etcd.service
mkdir -p /var/lib/etcd
service etcd start

ps -ef|grep etcd
# journalctl -f -u etcd.service
```



### 4. å®‰è£…ApiServer(Master)

```shell
cp target/master-node/kube-apiserver.service /lib/systemd/system/
systemctl enable kube-apiserver.service
service kube-apiserver start
ps -ef|grep kube-apiserver
# journalctl -f -u kube-apiserver
```

```bash
[Unit]
Description=Kubernetes API Server
...
[Service]
#å¯æ‰§è¡Œæ–‡ä»¶çš„ä½ç½®
ExecStart=/home/michael/bin/kube-apiserver \
#éå®‰å…¨ç«¯å£(8080)ç»‘å®šçš„ç›‘å¬åœ°å€ è¿™é‡Œè¡¨ç¤ºç›‘å¬æ‰€æœ‰åœ°å€
--insecure-bind-address=0.0.0.0 \
#ä¸ä½¿ç”¨https
--kubelet-https=false \
#kubernetesé›†ç¾¤çš„è™šæ‹Ÿipçš„åœ°å€èŒƒå›´
--service-cluster-ip-range=10.68.0.0/16 \
#serviceçš„nodeportçš„ç«¯å£èŒƒå›´é™åˆ¶
--service-node-port-range=20000-40000 \
#å¾ˆå¤šåœ°æ–¹éƒ½éœ€è¦å’Œetcdæ‰“äº¤é“ï¼Œä¹Ÿæ˜¯å”¯ä¸€å¯ä»¥ç›´æ¥æ“ä½œetcdçš„æ¨¡å—
--etcd-servers=http://192.168.1.102:2379 \
```



### 5. å®‰è£…ControllerManager(Master)

```bash
cp target/master-node/kube-controller-manager.service /lib/systemd/system/
systemctl enable kube-controller-manager.service
service kube-controller-manager start
ps -ef|grep kube-controller-manager
#journalctl -f -u kube-controller-manager
```

**é‡ç‚¹é…ç½®è¯´æ˜:**

```bash
$ cat /lib/systemd/system/kube-controller-manager.service

[Unit]
Description=Kubernetes Controller Manager
...
[Service]
ExecStart=/home/michael/bin/kube-controller-manager \
\#å¯¹å¤–æœåŠ¡çš„ç›‘å¬åœ°å€ï¼Œè¿™é‡Œè¡¨ç¤ºåªæœ‰æœ¬æœºçš„ç¨‹åºå¯ä»¥è®¿é—®å®ƒ
--address=127.0.0.1 \
\#apiserverçš„url
--master=http://127.0.0.1:8080 \
\#æœåŠ¡è™šæ‹ŸipèŒƒå›´ï¼ŒåŒapiserverçš„é…ç½®
--service-cluster-ip-range=10.68.0.0/16 \
\#podçš„ipåœ°å€èŒƒå›´
--cluster-cidr=172.20.0.0/16 \
\#ä¸‹é¢ä¸¤ä¸ªè¡¨ç¤ºä¸ä½¿ç”¨è¯ä¹¦ï¼Œç”¨ç©ºå€¼è¦†ç›–é»˜è®¤å€¼
--cluster-signing-cert-file= \
--cluster-signing-key-file= \
...
```





### 6. å®‰è£…Scheduler(Master)

>   `kube-scheduler`è´Ÿè´£åˆ†é…è°ƒåº¦Podåˆ°é›†ç¾¤å†…çš„èŠ‚ç‚¹ä¸Šï¼Œå®ƒç›‘å¬kube-apiserverï¼ŒæŸ¥è¯¢è¿˜æœªåˆ†é…Nodeçš„Podï¼Œç„¶åæ ¹æ®è°ƒåº¦ç­–ç•¥ä¸ºè¿™äº›Podåˆ†é…èŠ‚ç‚¹ã€‚æˆ‘ä»¬å‰é¢è®²åˆ°çš„kubernetesçš„å„ç§è°ƒåº¦ç­–ç•¥å°±æ˜¯å®ƒå®ç°çš„ã€‚

**å®‰è£…å‘½ä»¤ï¼š**

```bash
cp target/master-node/kube-scheduler.service /lib/systemd/system/
systemctl enable kube-scheduler.service
service kube-scheduler start
ps -ef|grep kube-scheduler
# journalctl -f -u kube-scheduler
```

**é…ç½®è¯´æ˜ï¼š**

```bash
[Unit]
Description=Kubernetes Scheduler
...
[Service]
ExecStart=/home/michael/bin/kube-scheduler \
\#å¯¹å¤–æœåŠ¡çš„ç›‘å¬åœ°å€ï¼Œè¿™é‡Œè¡¨ç¤ºåªæœ‰æœ¬æœºçš„ç¨‹åºå¯ä»¥è®¿é—®å®ƒ
--address=127.0.0.1 \
\#apiserverçš„url
--master=http://127.0.0.1:8080 \
...
```



### 7. éƒ¨ç½²CalicoNode(All)

>   Calicoå®ç°äº†CNIæ¥å£ï¼Œæ˜¯kubernetesç½‘ç»œæ–¹æ¡ˆçš„ä¸€ç§é€‰æ‹©ï¼Œå®ƒä¸€ä¸ªçº¯ä¸‰å±‚çš„æ•°æ®ä¸­å¿ƒç½‘ç»œæ–¹æ¡ˆï¼ˆä¸éœ€è¦Overlayï¼‰ï¼Œå¹¶ä¸”ä¸OpenStackã€Kubernetesã€AWSã€GCEç­‰IaaSå’Œå®¹å™¨å¹³å°éƒ½æœ‰è‰¯å¥½çš„é›†æˆã€‚ Calicoåœ¨æ¯ä¸€ä¸ªè®¡ç®—èŠ‚ç‚¹åˆ©ç”¨Linux  Kernelå®ç°äº†ä¸€ä¸ªé«˜æ•ˆçš„vRouteræ¥è´Ÿè´£æ•°æ®è½¬å‘ï¼Œè€Œæ¯ä¸ªvRouteré€šè¿‡BGPåè®®è´Ÿè´£æŠŠè‡ªå·±ä¸Šè¿è¡Œçš„workloadçš„è·¯ç”±ä¿¡æ¯åƒæ•´ä¸ªCalicoç½‘ç»œå†…ä¼ æ’­â€”â€”å°è§„æ¨¡éƒ¨ç½²å¯ä»¥ç›´æ¥äº’è”ï¼Œå¤§è§„æ¨¡ä¸‹å¯é€šè¿‡æŒ‡å®šçš„BGP route reflectoræ¥å®Œæˆã€‚ è¿™æ ·ä¿è¯æœ€ç»ˆæ‰€æœ‰çš„workloadä¹‹é—´çš„æ•°æ®æµé‡éƒ½æ˜¯é€šè¿‡IPè·¯ç”±çš„æ–¹å¼å®Œæˆäº’è”çš„ã€‚

**calicoæ˜¯é€šè¿‡ç³»ç»ŸæœåŠ¡+dockeræ–¹å¼å®Œæˆçš„**

```bash
cp target/all-node/kube-calico.service /lib/systemd/system/
systemctl enable kube-calico.service
service kube-calico start
# journalctl -f -u kube-calico
```

**æŸ¥çœ‹å®¹å™¨è¿è¡Œæƒ…å†µ**

```bash
$ docker ps
CONTAINER ID   IMAGE                COMMAND        CREATED ...
4d371b58928b   calico/node:v2.6.2   "start_runit"  3 hours ago...
```

**æŸ¥çœ‹èŠ‚ç‚¹è¿è¡Œæƒ…å†µ**

```bash
[root@vm01 kubernetes-starter]# /root/k8s/calicoctl node status
Calico process is running.

IPv4 BGP status
+--------------+-------------------+-------+----------+-------------+
| PEER ADDRESS |     PEER TYPE     | STATE |  SINCE   |    INFO     |
+--------------+-------------------+-------+----------+-------------+
| 10.0.0.12    | node-to-node mesh | up    | 20:23:22 | Established |
| 10.0.0.13    | node-to-node mesh | up    | 20:23:37 | Established |
+--------------+-------------------+-------+----------+-------------+

IPv6 BGP status
No IPv6 peers found.
```

**æŸ¥çœ‹ç«¯å£BGP åè®®æ˜¯é€šè¿‡TCP è¿æ¥æ¥å»ºç«‹é‚»å±…çš„ï¼Œå› æ­¤å¯ä»¥ç”¨netstat å‘½ä»¤éªŒè¯ BGP Peer**

```bash
$ netstat -natp|grep ESTABLISHED|grep 179
tcp        0      0 192.168.1.102:60959     192.168.1.103:179       ESTABLISHED 29680/bird
```

**æŸ¥çœ‹é›†ç¾¤ippoolæƒ…å†µ**

```
$ calicoctl get ipPool -o yaml
- apiVersion: v1
  kind: ipPool
  metadata:
    cidr: 172.20.0.0/16
  spec:
    nat-outgoing: true
```

5.4 é‡ç‚¹é…ç½®è¯´æ˜

```bash
[Unit]
Description=calico node
...
[Service]
\#ä»¥dockeræ–¹å¼è¿è¡Œ
ExecStart=/usr/bin/docker run --net=host --privileged --name=calico-node \
\#æŒ‡å®šetcd endpointsï¼ˆè¿™é‡Œä¸»è¦è´Ÿè´£ç½‘ç»œå…ƒæ•°æ®ä¸€è‡´æ€§ï¼Œç¡®ä¿Calicoç½‘ç»œçŠ¶æ€çš„å‡†ç¡®æ€§ï¼‰
-e ETCD_ENDPOINTS=http://192.168.1.102:2379 \
\#ç½‘ç»œåœ°å€èŒƒå›´ï¼ˆåŒä¸Šé¢ControllerManagerï¼‰
-e CALICO_IPV4POOL_CIDR=172.20.0.0/16 \
\#é•œåƒåï¼Œä¸ºäº†åŠ å¿«å¤§å®¶çš„ä¸‹è½½é€Ÿåº¦ï¼Œé•œåƒéƒ½æ”¾åˆ°äº†é˜¿é‡Œäº‘ä¸Š
registry.cn-hangzhou.aliyuncs.com/imooc/calico-node:v2.6.2
```





### 8. é…ç½®kubectlå‘½ä»¤(Aay)

>   kubectlæ˜¯Kubernetesçš„å‘½ä»¤è¡Œå·¥å…·ï¼Œæ˜¯Kubernetesç”¨æˆ·å’Œç®¡ç†å‘˜å¿…å¤‡çš„ç®¡ç†å·¥å…·ã€‚ kubectlæä¾›äº†å¤§é‡çš„å­å‘½ä»¤ï¼Œæ–¹ä¾¿ç®¡ç†Kubernetesé›†ç¾¤ä¸­çš„å„ç§åŠŸèƒ½ã€‚

**kubectlåˆå§‹åŒ–ï¼š**

ä½¿ç”¨kubectlçš„ç¬¬ä¸€æ­¥æ˜¯é…ç½®Kubernetesé›†ç¾¤ä»¥åŠè®¤è¯æ–¹å¼ï¼ŒåŒ…æ‹¬ï¼š

-   clusterä¿¡æ¯ï¼šapi-serveråœ°å€
-   ç”¨æˆ·ä¿¡æ¯ï¼šç”¨æˆ·åã€å¯†ç æˆ–å¯†é’¥
-   Contextï¼šclusterã€ç”¨æˆ·ä¿¡æ¯ä»¥åŠNamespaceçš„ç»„åˆ

æˆ‘ä»¬è¿™æ²¡æœ‰å®‰å…¨ç›¸å…³çš„ä¸œè¥¿ï¼Œåªéœ€è¦è®¾ç½®å¥½api-serverå’Œä¸Šä¸‹æ–‡å°±å¥½å•¦ï¼š

```bash
#æŒ‡å®šapiserveråœ°å€ï¼ˆipæ›¿æ¢ä¸ºä½ è‡ªå·±çš„api-serveråœ°å€ï¼‰
kubectl config set-cluster kubernetes  --server=http://10.0.0.11:8080
#æŒ‡å®šè®¾ç½®ä¸Šä¸‹æ–‡ï¼ŒæŒ‡å®šcluster
kubectl config set-context kubernetes --cluster=kubernetes
#é€‰æ‹©é»˜è®¤çš„ä¸Šä¸‹æ–‡
kubectl config use-context kubernetes
```

>   é€šè¿‡ä¸Šé¢çš„è®¾ç½®æœ€ç»ˆç›®çš„æ˜¯ç”Ÿæˆäº†ä¸€ä¸ªé…ç½®æ–‡ä»¶ï¼š~/.kube/configï¼Œå½“ç„¶ä½ ä¹Ÿå¯ä»¥æ‰‹å†™æˆ–å¤åˆ¶ä¸€ä¸ªæ–‡ä»¶æ”¾åœ¨é‚£ï¼Œå°±ä¸éœ€è¦ä¸Šé¢çš„å‘½ä»¤äº†ã€‚



### 9. é…ç½®kubelet(Worker)

>   æ¯ä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šéƒ½è¿è¡Œä¸€ä¸ªkubeletæœåŠ¡è¿›ç¨‹ï¼Œé»˜è®¤ç›‘å¬10250ç«¯å£ï¼Œæ¥æ”¶å¹¶æ‰§è¡Œmasterå‘æ¥çš„æŒ‡ä»¤ï¼Œç®¡ç†PodåŠPodä¸­çš„å®¹å™¨ã€‚æ¯ä¸ªkubeletè¿›ç¨‹ä¼šåœ¨API Serverä¸Šæ³¨å†ŒèŠ‚ç‚¹è‡ªèº«ä¿¡æ¯ï¼Œå®šæœŸå‘masterèŠ‚ç‚¹æ±‡æŠ¥èŠ‚ç‚¹çš„èµ„æºä½¿ç”¨æƒ…å†µï¼Œå¹¶é€šè¿‡cAdvisorç›‘æ§èŠ‚ç‚¹å’Œå®¹å™¨çš„èµ„æºã€‚

```bash
#ç¡®ä¿ç›¸å…³ç›®å½•å­˜åœ¨
mkdir -p /var/lib/kubelet
mkdir -p /etc/kubernetes
mkdir -p /etc/cni/net.d

#å¤åˆ¶kubeletæœåŠ¡é…ç½®æ–‡ä»¶
cp target/worker-node/kubelet.service /lib/systemd/system/
#å¤åˆ¶kubeletä¾èµ–çš„é…ç½®æ–‡ä»¶
cp target/worker-node/kubelet.kubeconfig /etc/kubernetes/
#å¤åˆ¶kubeletç”¨åˆ°çš„cniæ’ä»¶é…ç½®æ–‡ä»¶
cp target/worker-node/10-calico.conf /etc/cni/net.d/

systemctl enable kubelet.service
service kubelet start
ps -ef|grep kubelet
#journalctl -f -u kubelet
```

**é‡ç‚¹é…ç½®è¯´æ˜:**

```bash
[Unit]
Description=Kubernetes Kubelet
[Service]
\#kubeletå·¥ä½œç›®å½•ï¼Œå­˜å‚¨å½“å‰èŠ‚ç‚¹å®¹å™¨ï¼Œpodç­‰ä¿¡æ¯
WorkingDirectory=/var/lib/kubelet
ExecStart=/home/michael/bin/kubelet \
\#å¯¹å¤–æœåŠ¡çš„ç›‘å¬åœ°å€
--address=192.168.1.103 \
\#æŒ‡å®šåŸºç¡€å®¹å™¨çš„é•œåƒï¼Œè´Ÿè´£åˆ›å»ºPod å†…éƒ¨å…±äº«çš„ç½‘ç»œã€æ–‡ä»¶ç³»ç»Ÿç­‰ï¼Œè¿™ä¸ªåŸºç¡€å®¹å™¨éå¸¸é‡è¦ï¼šK8Sæ¯ä¸€ä¸ªè¿è¡Œçš„ PODé‡Œé¢å¿…ç„¶åŒ…å«è¿™ä¸ªåŸºç¡€å®¹å™¨ï¼Œå¦‚æœå®ƒæ²¡æœ‰è¿è¡Œèµ·æ¥é‚£ä¹ˆä½ çš„POD è‚¯å®šåˆ›å»ºä¸äº†
--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/imooc/pause-amd64:3.0 \
\#è®¿é—®é›†ç¾¤æ–¹å¼çš„é…ç½®ï¼Œå¦‚api-serveråœ°å€ç­‰
--kubeconfig=/etc/kubernetes/kubelet.kubeconfig \
\#å£°æ˜cniç½‘ç»œæ’ä»¶
--network-plugin=cni \
\#cniç½‘ç»œé…ç½®ç›®å½•ï¼Œkubeletä¼šè¯»å–è¯¥ç›®å½•ä¸‹å¾—ç½‘ç»œé…ç½®
--cni-conf-dir=/etc/cni/net.d \
\#æŒ‡å®š kubedns çš„ Service IP(å¯ä»¥å…ˆåˆ†é…ï¼Œåç»­åˆ›å»º kubedns æœåŠ¡æ—¶æŒ‡å®šè¯¥ IP)ï¼Œ--cluster-domain æŒ‡å®šåŸŸååç¼€ï¼Œè¿™ä¸¤ä¸ªå‚æ•°åŒæ—¶æŒ‡å®šåæ‰ä¼šç”Ÿæ•ˆ
--cluster-dns=10.68.0.2 \
...
```



**kubelet.kubeconfig**
kubeletä¾èµ–çš„ä¸€ä¸ªé…ç½®ï¼Œæ ¼å¼çœ‹ä¹Ÿæ˜¯æˆ‘ä»¬åé¢ç»å¸¸é‡åˆ°çš„yamlæ ¼å¼ï¼Œæè¿°äº†kubeletè®¿é—®apiserverçš„æ–¹å¼

>   apiVersion: v1
>    clusters:
>    \- cluster:
>    \#è·³è¿‡tlsï¼Œå³æ˜¯kubernetesçš„è®¤è¯
>    insecure-skip-tls-verify: true
>    \#api-serveråœ°å€
>    server: http://192.168.1.102:8080
>    ...

**10-calico.conf**
calicoä½œä¸ºkubernetsçš„CNIæ’ä»¶çš„é…ç½®

```conf
{  
  "name": "calico-k8s-network",  
  "cniVersion": "0.1.0",  
  "type": "calico",  
    <!--etcdçš„url-->
    "ed_endpoints": "http://192.168.1.102:2379",  
    "logevel": "info",  
    "ipam": {  
        "type": "calico-ipam"  
   },  
    "kubernetes": {  
        <!--api-serverçš„url-->
        "k8s_api_root": "http://192.168.1.102:8080"  
    }  
}  
```



### 10. å¢åŠ kube-proxy(Worker)

>    æ¯å°å·¥ä½œèŠ‚ç‚¹ä¸Šéƒ½åº”è¯¥è¿è¡Œä¸€ä¸ªkube-proxyæœåŠ¡ï¼Œå®ƒç›‘å¬API serverä¸­serviceå’Œendpointçš„å˜åŒ–æƒ…å†µï¼Œå¹¶é€šè¿‡iptablesç­‰æ¥ä¸ºæœåŠ¡é…ç½®è´Ÿè½½å‡è¡¡ï¼Œæ˜¯è®©æˆ‘ä»¬çš„æœåŠ¡åœ¨é›†ç¾¤å¤–å¯ä»¥è¢«è®¿é—®åˆ°çš„é‡è¦æ–¹å¼ã€‚

```bash
#ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨
mkdir -p /var/lib/kube-proxy
#å¤åˆ¶kube-proxyæœåŠ¡é…ç½®æ–‡ä»¶
cp target/worker-node/kube-proxy.service /lib/systemd/system/
#å¤åˆ¶kube-proxyä¾èµ–çš„é…ç½®æ–‡ä»¶
cp target/worker-node/kube-proxy.kubeconfig /etc/kubernetes/

systemctl enable kube-proxy.service
service kube-proxy start
#journalctl -f -u kube-proxy
```

**é‡ç‚¹é…ç½®è¯´æ˜:**

**kube-proxy.service**

```bash
[Unit]
Description=Kubernetes Kube-Proxy Server ...
[Service]
\#å·¥ä½œç›®å½•
WorkingDirectory=/var/lib/kube-proxy
ExecStart=/home/michael/bin/kube-proxy \
\#ç›‘å¬åœ°å€
--bind-address=192.168.1.103 \
\#ä¾èµ–çš„é…ç½®æ–‡ä»¶ï¼Œæè¿°äº†kube-proxyå¦‚ä½•è®¿é—®api-server
--kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \
...
```



**kube-proxy.kubeconfig** é…ç½®äº†kube-proxyå¦‚ä½•è®¿é—®api-serverï¼Œå†…å®¹ä¸kubeleté›·åŒï¼Œä¸å†èµ˜è¿°ã€‚

åˆšæ‰æˆ‘ä»¬åœ¨åŸºç¡€é›†ç¾¤ä¸Šæ¼”ç¤ºäº†podï¼Œdeploymentsã€‚ä¸‹é¢å°±åœ¨åˆšæ‰çš„åŸºç¡€ä¸Šå¢åŠ ç‚¹serviceå…ƒç´ ã€‚å…·ä½“å†…å®¹è§[ã€ŠDocker+k8så¾®æœåŠ¡å®¹å™¨åŒ–å®è·µã€‹](https://coding.imooc.com/class/198.html)ã€‚



### 11. æ·»åŠ dnsåŠŸèƒ½

>   kube-dnsä¸ºKubernetesé›†ç¾¤æä¾›å‘½åæœåŠ¡ï¼Œä¸»è¦ç”¨æ¥è§£æé›†ç¾¤æœåŠ¡åå’ŒPodçš„hostnameã€‚ç›®çš„æ˜¯è®©podå¯ä»¥é€šè¿‡åå­—è®¿é—®åˆ°é›†ç¾¤å†…æœåŠ¡ã€‚å®ƒé€šè¿‡æ·»åŠ Aè®°å½•çš„æ–¹å¼å®ç°åå­—å’Œserviceçš„è§£æã€‚æ™®é€šçš„serviceä¼šè§£æåˆ°service-ipã€‚headless serviceä¼šè§£æåˆ°podåˆ—è¡¨ã€‚

```bash
# åˆ°kubernetes-starterç›®å½•æ‰§è¡Œå‘½ä»¤
kubectl create -f target/services/kube-dns.yaml
```

_é€šè¿‡dnsè®¿é—®æœåŠ¡:å…·ä½“å†…å®¹è¯·çœ‹[ã€ŠDocker+k8så¾®æœåŠ¡å®¹å™¨åŒ–å®è·µã€‹](https://coding.imooc.com/class/198.html)_



<br/>


## Kubeadminå®‰è£…

### ç¬¬ 1 æ­¥ - åˆå§‹åŒ– Master

```bash
kubeadm init --token=102952.1a7dd4cc8d1f4cc5 --kubernetes-version $(kubeadm version -o short)

sudo cp /etc/kubernetes/admin.conf $HOME/
sudo chown $(id -u):$(id -g) $HOME/admin.conf
export KUBECONFIG=$HOME/admin.conf
```



### ç¬¬ 2 æ­¥ - éƒ¨ç½²å®¹å™¨ç½‘ç»œæ¥å£ (CNI)

å®¹å™¨ç½‘ç»œæ¥å£ (CNI) å®šä¹‰äº†ä¸åŒèŠ‚ç‚¹åŠå…¶å·¥ä½œè´Ÿè½½åº”å¦‚ä½•é€šä¿¡, some are listed [here](https://kubernetes.io/docs/admin/addons/).

```bash
kubectl apply -f /opt/weave-kube.yaml
kubectl get pod -n kube-system
```
_weave-kube.yaml_
```yaml
apiVersion: v1
kind: List
items:
  - apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: weave-net
      annotations:
        cloud.weave.works/launcher-info: |-
          {
            "original-request": {
              "url": "/k8s/v1.10/net.yaml?k8s-version=v1.16.0",
              "date": "Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)"
            },
            "email-address": "support@weave.works"
          }
      labels:
        name: weave-net
      namespace: kube-system
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: weave-net
      annotations:
        cloud.weave.works/launcher-info: |-
          {
            "original-request": {
              "url": "/k8s/v1.10/net.yaml?k8s-version=v1.16.0",
              "date": "Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)"
            },
            "email-address": "support@weave.works"
          }
      labels:
        name: weave-net
    rules:
      - apiGroups:
          - ''
        resources:
          - pods
          - namespaces
          - nodes
        verbs:
          - get
          - list
          - watch
      - apiGroups:
          - networking.k8s.io
        resources:
          - networkpolicies
        verbs:
          - get
          - list
          - watch
      - apiGroups:
          - ''
        resources:
          - nodes/status
        verbs:
          - patch
          - update
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: weave-net
      annotations:
        cloud.weave.works/launcher-info: |-
          {
            "original-request": {
              "url": "/k8s/v1.10/net.yaml?k8s-version=v1.16.0",
              "date": "Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)"
            },
            "email-address": "support@weave.works"
          }
      labels:
        name: weave-net
    roleRef:
      kind: ClusterRole
      name: weave-net
      apiGroup: rbac.authorization.k8s.io
    subjects:
      - kind: ServiceAccount
        name: weave-net
        namespace: kube-system
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: Role
    metadata:
      name: weave-net
      annotations:
        cloud.weave.works/launcher-info: |-
          {
            "original-request": {
              "url": "/k8s/v1.10/net.yaml?k8s-version=v1.16.0",
              "date": "Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)"
            },
            "email-address": "support@weave.works"
          }
      labels:
        name: weave-net
      namespace: kube-system
    rules:
      - apiGroups:
          - ''
        resourceNames:
          - weave-net
        resources:
          - configmaps
        verbs:
          - get
          - update
      - apiGroups:
          - ''
        resources:
          - configmaps
        verbs:
          - create
  - apiVersion: rbac.authorization.k8s.io/v1
    kind: RoleBinding
    metadata:
      name: weave-net
      annotations:
        cloud.weave.works/launcher-info: |-
          {
            "original-request": {
              "url": "/k8s/v1.10/net.yaml?k8s-version=v1.16.0",
              "date": "Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)"
            },
            "email-address": "support@weave.works"
          }
      labels:
        name: weave-net
      namespace: kube-system
    roleRef:
      kind: Role
      name: weave-net
      apiGroup: rbac.authorization.k8s.io
    subjects:
      - kind: ServiceAccount
        name: weave-net
        namespace: kube-system
  - apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: weave-net
      annotations:
        cloud.weave.works/launcher-info: |-
          {
            "original-request": {
              "url": "/k8s/v1.10/net.yaml?k8s-version=v1.16.0",
              "date": "Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)"
            },
            "email-address": "support@weave.works"
          }
      labels:
        name: weave-net
      namespace: kube-system
    spec:
      minReadySeconds: 5
      selector:
        matchLabels:
          name: weave-net
      template:
        metadata:
          labels:
            name: weave-net
        spec:
          containers:
            - name: weave
              command:
                - /home/weave/launch.sh
              env:
                - name: IPALLOC_RANGE
                  value: 10.32.0.0/24
                - name: HOSTNAME
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: spec.nodeName
              image: 'docker.io/weaveworks/weave-kube:2.6.0'
              readinessProbe:
                httpGet:
                  host: 127.0.0.1
                  path: /status
                  port: 6784
              resources:
                requests:
                  cpu: 10m
              securityContext:
                privileged: true
              volumeMounts:
                - name: weavedb
                  mountPath: /weavedb
                - name: cni-bin
                  mountPath: /host/opt
                - name: cni-bin2
                  mountPath: /host/home
                - name: cni-conf
                  mountPath: /host/etc
                - name: dbus
                  mountPath: /host/var/lib/dbus
                - name: lib-modules
                  mountPath: /lib/modules
                - name: xtables-lock
                  mountPath: /run/xtables.lock
            - name: weave-npc
              env:
                - name: HOSTNAME
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: spec.nodeName
              image: 'docker.io/weaveworks/weave-npc:2.6.0'
              resources:
                requests:
                  cpu: 10m
              securityContext:
                privileged: true
              volumeMounts:
                - name: xtables-lock
                  mountPath: /run/xtables.lock
          hostNetwork: true
          hostPID: true
          restartPolicy: Always
          securityContext:
            seLinuxOptions: {}
          serviceAccountName: weave-net
          tolerations:
            - effect: NoSchedule
              operator: Exists
          volumes:
            - name: weavedb
              hostPath:
                path: /var/lib/weave
            - name: cni-bin
              hostPath:
                path: /opt
            - name: cni-bin2
              hostPath:
                path: /home
            - name: cni-conf
              hostPath:
                path: /etc
            - name: dbus
              hostPath:
                path: /var/lib/dbus
            - name: lib-modules
              hostPath:
                path: /lib/modules
            - name: xtables-lock
              hostPath:
                path: /run/xtables.lock
                type: FileOrCreate
      updateStrategy:
        type: RollingUpdate
```
>   When installing Weave on your cluster, visit https://www.weave.works/docs/net/latest/kube-addon/ for details.



### ç¬¬ 3 æ­¥ - åŠ å…¥é›†ç¾¤

ä¸€æ—¦ Master å’Œ CNI åˆå§‹åŒ–ï¼Œå…¶ä»–èŠ‚ç‚¹åªè¦æœ‰æ­£ç¡®çš„ä»¤ç‰Œå°±å¯ä»¥åŠ å…¥é›†ç¾¤ã€‚  ä»¤ç‰Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ç®¡ç†  `kubeadm token`ï¼Œ ä¾‹å¦‚  `kubeadm token list`.

åœ¨ç¬¬äºŒä¸ªèŠ‚ç‚¹ä¸Šï¼Œè¿è¡Œå‘½ä»¤åŠ å…¥é›†ç¾¤ï¼Œæä¾›ä¸»èŠ‚ç‚¹çš„ IP åœ°å€ã€‚

```bash
kubeadm join --discovery-token-unsafe-skip-ca-verification --token=102952.1a7dd4cc8d1f4cc5 172.17.0.87:6443
```

è¿™ä¸ Master åˆå§‹åŒ–åæä¾›çš„å‘½ä»¤ç›¸åŒã€‚

è¿™  `--discovery-token-unsafe-skip-ca-verification`æ ‡ç­¾ç”¨äºç»•è¿‡ Discovery Token éªŒè¯ã€‚  ç”±äºæ­¤ä»¤ç‰Œæ˜¯åŠ¨æ€ç”Ÿæˆçš„ï¼Œå› æ­¤æˆ‘ä»¬æ— æ³•å°†å…¶åŒ…å«åœ¨æ­¥éª¤ä¸­ã€‚  åœ¨ç”Ÿäº§ä¸­ï¼Œä½¿ç”¨æä¾›çš„ä»¤ç‰Œ  `kubeadm init`.



### ç¬¬ 4 æ­¥ - æŸ¥çœ‹èŠ‚ç‚¹

```bash
kubectl get nodes
```



### ç¬¬ 5 æ­¥ - éƒ¨ç½² Pod

```
kubectl create deployment http --image=katacoda/docker-http-server:latest
kubectl get pods
docker ps | grep docker-http-server
```



### ç¬¬ 6 æ­¥ - éƒ¨ç½²ä»ªè¡¨æ¿

Kubernetes æœ‰ä¸€ä¸ªåŸºäº Web çš„ä»ªè¡¨æ¿ UIï¼Œæä¾›å¯¹ Kubernetes é›†ç¾¤çš„å¯è§æ€§ã€‚

ä½¿ç”¨å‘½ä»¤éƒ¨ç½²ä»ªè¡¨æ¿ yaml  `kubectl apply -f dashboard.yaml`

ä»ªè¡¨æ¿éƒ¨ç½²åˆ° *kube-system* å‘½åç©ºé—´ä¸­ã€‚ æŸ¥çœ‹éƒ¨ç½²çŠ¶æ€ `kubectl get pods -n kube-system`

éœ€è¦ ServiceAccount æ‰èƒ½ç™»å½•ã€‚ ClusterRoleBinding ç”¨äºä¸ºæ–°çš„ ServiceAccount ( åˆ†é… *admin-user* ) è§’è‰² *é›†ç¾¤ -admin* ä¸Šçš„ cluster ã€‚

```
cat <<EOF | kubectl create -f - 
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kube-system
EOF
```

è¿™æ„å‘³ç€ä»–ä»¬å¯ä»¥æ§åˆ¶ Kubernetes çš„æ‰€æœ‰æ–¹é¢ã€‚ é€šè¿‡ ClusterRoleBinding å’Œ RBACï¼Œå¯ä»¥æ ¹æ®å®‰å…¨è¦æ±‚å®šä¹‰ä¸åŒçº§åˆ«çš„æƒé™ã€‚ æœ‰å…³ä¸ºä»ªè¡¨æ¿åˆ›å»ºç”¨æˆ·çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ [ä»ªè¡¨æ¿æ–‡æ¡£ ](https://github.com/kubernetes/dashboard/wiki/Creating-sample-user)ã€‚

åˆ›å»º ServiceAccount åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ‰¾åˆ°ç™»å½•ä»¤ç‰Œï¼š

```bash
kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')
```

éƒ¨ç½²ä»ªè¡¨æ¿æ—¶ï¼Œå®ƒä½¿ç”¨ externalIPs å°†æœåŠ¡ç»‘å®šåˆ°ç«¯å£ 8443ã€‚è¿™ä½¿å¾—ä»ªè¡¨æ¿å¯ä¾›é›†ç¾¤å¤–éƒ¨ä½¿ç”¨ï¼Œå¹¶å¯åœ¨ æŸ¥çœ‹ [https://2886795352-8443-cykoria04.environments.katacoda.com/ ](https://2886795352-8443-cykoria04.environments.katacoda.com/)

ä½¿ç”¨ *ç®¡ç†å‘˜ç”¨æˆ·* ä»¤ç‰Œè®¿é—®ä»ªè¡¨æ¿ã€‚

å¯¹äºç”Ÿäº§ï¼Œå»ºè®®ä½¿ç”¨è€Œä¸æ˜¯ externalIPs  `kubectl proxy`è®¿é—®ä»ªè¡¨æ¿ã€‚ åœ¨ æŸ¥çœ‹æ›´å¤šè¯¦ç»†ä¿¡æ¯ [https://github.com/kubernetes/dashboard ä¸Š ](https://github.com/kubernetes/dashboard)ã€‚



---



```bash
$ kubeadm init --token=102952.1a7dd4cc8d1f4cc5 --kubernetes-version $(kubeadm version -o short)
[init] Using Kubernetes version: v1.14.0
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Activating the kubelet service
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [controlplane kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.17.0.56]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [controlplane localhost] and IPs [172.17.0.56 127.0.0.1 ::1]
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [controlplane localhost] and IPs [172.17.0.56 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
[control-plane] Creating static Pod manifest for "kube-scheduler"
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
[apiclient] All control plane components are healthy after 20.504376 seconds
[upload-config] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config-1.14" in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --experimental-upload-certs
[mark-control-plane] Marking the node controlplane as control-plane by adding the label "node-role.kubernetes.io/master=''"
[mark-control-plane] Marking the node controlplane as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: 102952.1a7dd4cc8d1f4cc5
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] creating the "cluster-info" ConfigMap in the "kube-public" namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

$ kubeadm join 172.17.0.56:6443 --token 102952.1a7dd4cc8d1f4cc5 \
    --discovery-token-ca-cert-hash sha256:1769836f75a258befcb5d79dcc6624b159157771176321492e67e4304bcd5dc1 
controlplane $ 

$ sudo cp /etc/kubernetes/admin.conf $HOME/
$ sudo chown $(id -u):$(id -g) $HOME/admin.conf
$ export KUBECONFIG=$HOME/admin.conf


$ kubectl apply -f /opt/weave-kube.yaml
serviceaccount/weave-net created
clusterrole.rbac.authorization.k8s.io/weave-net created
clusterrolebinding.rbac.authorization.k8s.io/weave-net created
role.rbac.authorization.k8s.io/weave-net created
rolebinding.rbac.authorization.k8s.io/weave-net created
daemonset.apps/weave-net created

$ kubectl get pod -n kube-system
NAME                                   READY   STATUS    RESTARTS   AGE
coredns-fb8b8dccf-nq4sc                1/1     Running   0          2m41s
coredns-fb8b8dccf-wwb25                1/1     Running   0          2m41s
etcd-controlplane                      1/1     Running   0          98s
kube-apiserver-controlplane            1/1     Running   0          110s
kube-controller-manager-controlplane   1/1     Running   0          98s
kube-proxy-8tvbq                       1/1     Running   0          2m41s
kube-scheduler-controlplane            1/1     Running   1          118s
weave-net-xx6dc                        2/2     Running   0          34s

# On the second node, run the command to join the cluster providing the IP address of the Master node.
$ kubeadm join --discovery-token-unsafe-skip-ca-verification --token=102952.1a7dd4cc8d1f4cc5 172.17.0.56:6443
 
$ kubectl create deployment http --image=katacoda/docker-http-server:latest
```









## å‚è€ƒé“¾æ¥

https://kubernetes.io/zh/docs/tasks/tools/install-kubectl/
https://blog.csdn.net/wangtonglin2009/article/details/79024820
https://blog.csdn.net/weixin_43420337/article/details/88571744
https://blog.csdn.net/wt334502157/article/details/83992120
https://blog.csdn.net/liuyunshengsir/article/details/89525458
https://blog.csdn.net/liumiaocn/article/details/104144132

https://blog.csdn.net/weixin_30649641/article/details/96451363



> https://github.com/liuyi01/kubernetes-starter


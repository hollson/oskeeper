# 服务器指标监控方案

[TOC]


## 📋 一、场景概述

在企业级生产环境中，需要周期性监控采集多个服务器的各种性能指标（CPU、网络、内存、进程等）。系统需要具备以下功能：

- 周期性数据采集（秒级或分钟级）
- 高效数据写入能力
- 按时间段查询和聚合统计
- 支持降采样处理（如从秒级数据生成分钟级、小时级汇总）
- 过期数据管理和清理
- 为Grafana等可视化平台提供数据查询接口



<br/>


## 🦆 二、DuckDB 方案

### 2.1 技术特点

DuckDB是一个嵌入式SQL OLAP数据库，专为分析工作负载设计，具有以下特点：
- 列式存储和向量化执行引擎
- 单文件数据库，零依赖部署
- 与Python/Pandas生态无缝集成
- 完整的SQL支持，包括时间序列函数
- 使用C++编写，无运行时依赖

### 2.2 优势

1. **部署简单**：单文件数据库，无需额外服务，易于部署和维护
2. **SQL友好**：完全兼容标准SQL，开发人员学习成本低
3. **时间序列支持**：提供丰富的日期时间函数和窗口函数
4. **内存效率**：列式存储适合时间序列数据的聚合查询
5. **生态系统**：与Python数据科学栈完美集成
6. **多连接支持**：支持独立连接实现读写分离

### 2.3 实施示例

```python
import duckdb
import threading
from datetime import datetime

class PerformanceMonitor:
    def __init__(self, db_path="perf_monitor.duckdb"):
        self.db_path = db_path
        self.setup_database()
    
    def setup_database(self):
        conn = duckdb.connect(self.db_path)
        # 创建时间序列表
        conn.execute("""
            CREATE TABLE IF NOT EXISTS server_metrics (
                timestamp TIMESTAMP,
                server_id VARCHAR,
                cpu_percent FLOAT,
                memory_percent FLOAT,
                disk_percent FLOAT,
                network_bytes_sent BIGINT,
                network_bytes_recv BIGINT
            )
        """)
        conn.close()
    
    def collect_and_write(self, server_id, metrics):
        """采集并写入性能指标"""
        conn = duckdb.connect(self.db_path)
        conn.execute("""
            INSERT INTO server_metrics 
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, [
            datetime.now(),
            server_id,
            metrics['cpu'],
            metrics['memory'],
            metrics['disk'],
            metrics['net_sent'],
            metrics['net_recv']
        ])
        conn.close()

class QueryAnalyzer:
    def __init__(self, db_path="perf_monitor.duckdb"):
        self.db_path = db_path
    
    def get_cpu_avg_by_server(self, server_id, hours=1):
        """获取指定服务器CPU平均使用率"""
        conn = duckdb.connect(self.db_path)
        result = conn.execute("""
            SELECT AVG(cpu_percent) as avg_cpu
            FROM server_metrics 
            WHERE server_id = ? AND 
                  timestamp >= CURRENT_TIMESTAMP - INTERVAL '{}' HOUR
        """, [server_id, str(hours)]).fetchone()[0]
        conn.close()
        return result if result is not None else 0.0
    
    def get_peak_memory(self, server_id, hours=1):
        """获取指定服务器内存峰值使用率"""
        conn = duckdb.connect(self.db_path)
        result = conn.execute("""
            SELECT MAX(memory_percent) as peak_memory
            FROM server_metrics 
            WHERE server_id = ? AND 
                  timestamp >= CURRENT_TIMESTAMP - INTERVAL '{}' HOUR
        """, [server_id, str(hours)]).fetchone()[0]
        conn.close()
        return result if result is not None else 0.0
    
    def get_time_series_data(self, server_id, start_time, end_time, interval='1 minute'):
        """获取时间序列数据，支持降采样"""
        conn = duckdb.connect(self.db_path)
        result = conn.execute(f"""
            SELECT 
                date_trunc('{interval}', timestamp) as time_bucket,
                AVG(cpu_percent) as avg_cpu,
                AVG(memory_percent) as avg_memory,
                MAX(cpu_percent) as max_cpu,
                MAX(memory_percent) as max_memory
            FROM server_metrics 
            WHERE server_id = ? AND 
                  timestamp BETWEEN ? AND ?
            GROUP BY time_bucket
            ORDER BY time_bucket
        """, [server_id, start_time, end_time]).df()
        conn.close()
        return result

    def get_sampled_data_for_grafana(self, server_id, days=90, sample_size=100):
        """获取降采样数据用于Grafana展示"""
        conn = duckdb.connect(self.db_path)
        
        # 计算总记录数，然后均匀采样
        total_count = conn.execute("""
            SELECT COUNT(*) as cnt
            FROM server_metrics 
            WHERE server_id = ? 
              AND timestamp >= CURRENT_DATE - INTERVAL '{}' DAY
        """, [server_id, str(days)]).fetchone()[0]
        
        if total_count <= sample_size:
            # 如果数据量小于等于采样数量，返回全部数据
            result = conn.execute("""
                SELECT timestamp, cpu_percent, memory_percent
                FROM server_metrics 
                WHERE server_id = ? 
                  AND timestamp >= CURRENT_DATE - INTERVAL '{}' DAY
                ORDER BY timestamp
            """, [server_id, str(days)]).df()
        else:
            # 否则进行均匀采样
            step = max(1, total_count // sample_size)
            result = conn.execute(f"""
                SELECT timestamp, cpu_percent, memory_percent
                FROM (
                    SELECT *,
                           ROW_NUMBER() OVER (ORDER BY timestamp) as rn
                    FROM server_metrics 
                    WHERE server_id = ? 
                      AND timestamp >= CURRENT_DATE - INTERVAL '{days}' DAY
                ) 
                WHERE rn % {step} = 1
                ORDER BY timestamp
                LIMIT {sample_size}
            """, [server_id]).df()
        
        conn.close()
        return result
```

### 2.4 局限性

1. **写入性能**：在极高频率写入场景下可能成为瓶颈
2. **并发限制**：单线程执行引擎，高并发写入时性能受限
3. **数据保留**：需要手动实现数据过期清理机制



<br/>




## 📊 三、CHDB 方案

### 3.1 技术特点

CHDB是基于ClickHouse的嵌入式OLAP引擎，具有以下特点：
- 继承ClickHouse的高性能分析能力
- 零拷贝机制，提升DataFrame处理性能
- 多线程并行处理
- 专门优化的时间序列数据处理能力
- 零依赖，嵌入式运行

### 3.2 优势

1. **查询性能**：查询速度通常比DuckDB更快
2. **写入性能**：多线程处理，适合高频数据写入
3. **压缩效率**：高效的列式存储和压缩算法，节省存储空间
4. **时间序列优化**：基于ClickHouse，对时间序列数据处理进行了专门优化
5. **零拷贝机制**：处理DataFrame时性能大幅提升

### 3.3 实施示例

```python
import chdb
import threading
from datetime import datetime

class CHDBPerformanceMonitor:
    def __init__(self, db_path="chdb_perf_monitor"):
        self.db_path = db_path
        self.setup_database()
    
    def setup_database(self):
        # CHDB支持直接在进程中处理数据
        session = chdb.Session()
        session.query("""
            CREATE TABLE IF NOT EXISTS server_metrics (
                timestamp DateTime,
                server_id String,
                cpu_percent Float32,
                memory_percent Float32,
                disk_percent Float32,
                network_bytes_sent UInt64,
                network_bytes_recv UInt64
            ) ENGINE = MergeTree()
            ORDER BY (server_id, timestamp)
        """)
    
    def collect_and_write(self, server_id, metrics):
        """采集并写入性能指标"""
        session = chdb.Session()
        session.query(f"""
            INSERT INTO server_metrics VALUES (
                now(),
                '{server_id}',
                {metrics['cpu']},
                {metrics['memory']},
                {metrics['disk']},
                {metrics['net_sent']},
                {metrics['net_recv']}
            )
        """)

class CHDBQueryAnalyzer:
    def __init__(self, db_path="chdb_perf_monitor"):
        self.session = chdb.Session()
    
    def get_cpu_avg_by_server(self, server_id, hours=1):
        """获取指定服务器CPU平均使用率"""
        result = self.session.query(f"""
            SELECT avg(cpu_percent) as avg_cpu
            FROM server_metrics 
            WHERE server_id = '{server_id}' AND 
                  timestamp >= now() - INTERVAL {hours} HOUR
        """)
        return result.values[0][0] if result.values else 0.0
    
    def get_time_series_data(self, server_id, start_time, end_time, interval='1 minute'):
        """获取时间序列数据，支持降采样"""
        result = self.session.query(f"""
            SELECT 
                toStartOfInterval(timestamp, INTERVAL {interval}) as time_bucket,
                avg(cpu_percent) as avg_cpu,
                avg(memory_percent) as avg_memory,
                max(cpu_percent) as max_cpu,
                max(memory_percent) as max_memory
            FROM server_metrics 
            WHERE server_id = '{server_id}' AND 
                  timestamp BETWEEN '{start_time}' AND '{end_time}'
            GROUP BY time_bucket
            ORDER BY time_bucket
        """)
        return result

    def get_sampled_data_for_grafana(self, server_id, days=90, sample_size=100):
        """获取降采样数据用于Grafana展示"""
        # 计算总记录数，然后均匀采样
        total_result = self.session.query(f"""
            SELECT count(*) as cnt
            FROM server_metrics 
            WHERE server_id = '{server_id}' 
              AND timestamp >= today() - INTERVAL {days} DAY
        """)
        total_count = total_result.values[0][0] if total_result.values else 0
        
        if total_count <= sample_size:
            # 如果数据量小于等于采样数量，返回全部数据
            result = self.session.query(f"""
                SELECT timestamp, cpu_percent, memory_percent
                FROM server_metrics 
                WHERE server_id = '{server_id}' 
                  AND timestamp >= today() - INTERVAL {days} DAY
                ORDER BY timestamp
            """)
        else:
            # 否则进行均匀采样 - 使用limit和offset配合
            step = max(1, total_count // sample_size)
            result = self.session.query(f"""
                SELECT timestamp, cpu_percent, memory_percent
                FROM (
                    SELECT *,
                           rowNumberInAllBlocks() as rn
                    FROM server_metrics 
                    WHERE server_id = '{server_id}' 
                      AND timestamp >= today() - INTERVAL {days} DAY
                    ORDER BY timestamp
                ) 
                WHERE (rn % {step}) = 1
                ORDER BY timestamp
                LIMIT {sample_size}
            """)
        return result
```

### 3.4 局限性

1. **成熟度**：相对较新，社区和工具链不如DuckDB成熟
2. **学习曲线**：可能需要更多配置和调优知识
3. **生态系统**：与数据分析生态的集成可能不如DuckDB完善



<br/>




## 📈 四、性能与降采样

### 4.1 基础性能

#### 4.1.1 写入性能
- **DuckDB**：适合中等频率写入（每秒数千次），批量写入性能优秀
- **CHDB**：适合高频率写入（每秒数万次），多线程处理能力强

#### 4.1.2 查询性能
- **DuckDB**：复杂聚合查询性能优秀，SQL兼容性好
- **CHDB**：简单查询和聚合查询速度更快，特别适合时间序列分析

#### 4.1.3 存储效率
- **DuckDB**：列式存储，压缩效率较高
- **CHDB**：继承ClickHouse的高压缩比，存储空间利用率更高

#### 4.1.4 并发处理
- **DuckDB**：支持多连接，但查询是串行执行
- **CHDB**：多线程并行处理，高并发场景下表现更好

### 4.2 降采样处理

#### 4.2.1 降采样技术实现

在服务器性能监控场景中，降采样是关键功能，特别是在展示长期趋势时（如过去三个月的数据）。以下是两种方案的降采样实现：

**DuckDB降采样实现**
1. **时间桶聚合**：使用`date_trunc`函数按时间间隔聚合数据
2. **均匀采样**：使用`ROW_NUMBER()`和模运算实现均匀数据点提取
3. **随机采样**：在大数据集中使用随机函数提取样本

**CHDB降采样实现**

1. **时间区间聚合**：使用`toStartOfInterval`函数进行时间桶分组
2. **高效采样**：利用ClickHouse优化的采样函数
3. **并行处理**：多线程并行执行降采样操作

#### 4.2.2 Grafana展示优化

针对Grafana图表展示需求（如从三个月数据中提取100个数据点），两种方案都能有效实现：

- **DuckDB方案**：适合中小规模数据，实现简单，SQL语法直观
- **CHDB方案**：适合大规模数据，处理速度快，内存效率高

#### 4.2.3 降采样性能对比

- **中小规模数据（GB级）**：DuckDB在降采样处理上性能足够，且实现更简单
- **大规模数据（TB级）**：CHDB在降采样处理上性能更优，特别是在并行计算方面



<br/>



## 💡 五、选择建议

### 5.1 推荐使用DuckDB的情况
- 中小规模监控（几十到数百台服务器）
- 注重开发效率和易用性
- 需要与Python数据科学栈深度集成
- 对SQL兼容性要求高
- 希望快速原型开发和部署
- 中小规模数据的降采样，Grafana展示优化

### 5.2 推荐使用CHDB的情况
- 大规模监控（数千台服务器以上）
- 对查询性能要求极高
- 已有ClickHouse技术栈
- 数据量巨大（TB级别）
- 需要最高程度的压缩和存储效率
- 大规模数据的高效降采样处理



<br/>




## 📋 六、实施总结

对于服务器性能指标监控场景，DuckDB和CHDB都是可行的解决方案，具体选择应基于以下因素：

1. **数据规模**：小到中等规模数据量（GB-TB级）推荐DuckDB；大规模数据（TB-PB级）推荐CHDB
2. **性能需求**：如果主要关注开发效率和易用性，选择DuckDB；如果追求极致查询性能，选择CHDB
3. **团队技能**：熟悉SQL和Python生态的团队更适合DuckDB；有ClickHouse经验的团队更适合CHDB
4. **集成需求**：需要与现有数据分析流程深度集成的场景更适合DuckDB
5. **降采样需求**：对于Grafana展示等降采样需求，中小规模数据推荐DuckDB，大规模数据推荐CHDB

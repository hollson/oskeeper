# æ•°æ®åº“å¹¶å‘æŒ‡å—

[TOC]


## ğŸ“š ä¸€ã€å¹¶å‘æœºåˆ¶

åµŒå…¥å¼æ•°æ®åº“ï¼ˆå¦‚ DuckDBã€SQLiteã€Redisï¼‰æ ¸å¿ƒä¸ºå•çº¿ç¨‹æ‰§è¡Œå¼•æ“ï¼Œä¸ä¼ ç»Ÿå®¢æˆ·ç«¯/æœåŠ¡ç«¯æ•°æ®åº“ï¼ˆå¦‚ PostgreSQLã€MySQLï¼‰çš„å¤šçº¿ç¨‹æ¶æ„å·®å¼‚æ˜¾è‘—ã€‚å…¶ IO æ¨¡å‹ä¸å¹¶å‘é€»è¾‘å›´ç»•å•çº¿ç¨‹ä¼˜åŒ–ï¼Œæ ¸å¿ƒåŸåˆ™ï¼š**å¼•æ“å†…ä¸²è¡Œæ‰§è¡Œä¿ä¸€è‡´ï¼Œé€šè¿‡ç‰¹å®šæœºåˆ¶æ”¯æŒå¤šè¿æ¥å¹¶å‘è®¿é—®**ã€‚

### 1.1 å¹¶å‘æ¨¡å‹

| æ•°æ®åº“ | æ‰§è¡Œå¼•æ“ç‰¹å¾               | å¹¶å‘è®¿é—®èƒ½åŠ›                     |
| ------ | -------------------------- | -------------------------------- |
| DuckDB | å•çº¿ç¨‹æŸ¥è¯¢æ‰§è¡Œ             | æ”¯æŒå¤šè¿æ¥å¹¶å‘ï¼ŒæŸ¥è¯¢ä¸²è¡Œè°ƒåº¦     |
| SQLite | é»˜è®¤å•çº¿ç¨‹ï¼ˆå¯æ‰©å±•å¤šçº¿ç¨‹ï¼‰ | æ–‡ä»¶çº§é”æ§åˆ¶ï¼Œåè°ƒè¯»å†™           |
| Redis  | å•çº¿ç¨‹äº‹ä»¶å¾ªç¯             | I/O å¤šè·¯å¤ç”¨å¤„ç†å¤šè¿æ¥ï¼Œå‘½ä»¤ä¸²è¡Œ |

### 1.2 å¹¶å‘æ§åˆ¶

**DuckDBå¹¶å‘ï¼š**

- å•å®ä¾‹å†…æŸ¥è¯¢ä¸²è¡Œæ‰§è¡Œï¼Œä¿è¯åŸå­æ€§
- é€šè¿‡ã€Œè¿æ¥çº§éš”ç¦» + MVCCã€å®ç°å¤šè¿æ¥å¹¶å‘
- æ— éœ€ç”¨æˆ·æ˜¾å¼åŠ é”ï¼Œå¼•æ“å†…éƒ¨åè°ƒå†²çª

**SQLiteå¹¶å‘ï¼š**

- åŸºäºæ–‡ä»¶çº§é”ï¼ˆå…±äº«/ç‹¬å ï¼‰å®ç°å¹¶å‘
- è¯»æ“ä½œå…±äº«é”ï¼Œæ”¯æŒå¹¶å‘è¯»
- å†™æ“ä½œç‹¬å é”ï¼Œäº’æ–¥ä¸”é˜»å¡å…¶ä»–è¯»å†™
- å¼€å¯ WAL æ¨¡å¼å¯ä¼˜åŒ–è¯»å†™å¹¶å‘ï¼ˆå†™ä¸é˜»å¡è¯»ï¼‰

**Rediså¹¶å‘ï¼š**

- å‘½ä»¤å•çº¿ç¨‹ä¸²è¡Œæ‰§è¡Œï¼Œå¤©ç„¶é¿å…å¹¶å‘å†²çª
- éé˜»å¡ I/O å¤šè·¯å¤ç”¨å¤„ç†å¤šè¿æ¥ï¼Œå®ç°å¹¶å‘
- æ— éœ€ä¼ ç»Ÿé”æœºåˆ¶ï¼Œé å•çº¿ç¨‹ä¿ä¸€è‡´

### 1.3 æ¦‚å¿µæ¾„æ¸…

> [!NOTE]
>
> **ã€Œä¸²è¡Œæ‰§è¡Œã€â‰  ä¸æ”¯æŒå¹¶å‘è®¿é—®**ã€‚1. ä¸²è¡Œæ˜¯å¼•æ“å†…éƒ¨ç‰¹æ€§ï¼Œä¿è¯æ“ä½œåŸå­æœ‰åºï¼›2. å¹¶å‘æ˜¯è¿æ¥å±‚é¢ç‰¹æ€§ï¼Œå¼•æ“é€šè¿‡é”/MVCC/é˜Ÿåˆ—åè°ƒï¼›3. å•æ–‡ä»¶å­˜å‚¨ä½†ä¾æ‰˜æ•°æ®åº“æœºåˆ¶ï¼Œå¹¶å‘èƒ½åŠ›è¿œè¶…æ™®é€šæ–‡ä»¶ã€‚



<br/>



## ğŸ’» äºŒã€å¹¶å‘ç¤ºä¾‹

ä»¥ä¸‹æä¾›ä¸‰ç§æ•°æ®åº“å¯å¤ç”¨çš„å¹¶å‘å®ç°æ–¹æ¡ˆï¼Œè¦†ç›–è¿æ¥ç®¡ç†ã€å¤šçº¿ç¨‹è¯»å†™ã€æ‰¹é‡æ“ä½œæ ¸å¿ƒåœºæ™¯ã€‚

### 2.1 DuckDBå¹¶å‘

```python
import duckdb
import threading
import time

class DuckDBConcurrentManager:
    def __init__(self, db_path="concurrent_db.duckdb"):
        self.db_path = db_path
        self._init_table()
    
    def _init_table(self):
        """åˆå§‹åŒ–metricsè¡¨"""
        with duckdb.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS metrics (
                    worker_id INTEGER,
                    value INTEGER,
                    timestamp DOUBLE
                )
            """)
    
    def writer_worker(self, worker_id):
        """å†™å…¥çº¿ç¨‹ï¼šç‹¬ç«‹è¿æ¥ï¼Œæ— éœ€æ˜¾å¼åŠ é”"""
        with duckdb.connect(self.db_path) as conn:
            for i in range(100):
                conn.execute(f"""
                    INSERT INTO metrics VALUES ({worker_id}, {i}, {time.time()})
                """)
        print(f"Writer {worker_id} å®Œæˆ")
    
    def reader_worker(self, worker_id):
        """è¯»å–çº¿ç¨‹ï¼šç‹¬ç«‹è¿æ¥ï¼Œæ”¯æŒå¹¶å‘è¯»"""
        with duckdb.connect(self.db_path) as conn:
            result = conn.execute("SELECT COUNT(*) FROM metrics").fetchone()
        print(f"Reader {worker_id} è¯»å–ç»“æœï¼šæ€»è®°å½•æ•° {result[0]}")
        return result[0]

## ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    manager = DuckDBConcurrentManager()
    
    # 3ä¸ªå†™çº¿ç¨‹ã€2ä¸ªè¯»çº¿ç¨‹
    writers = [threading.Thread(target=manager.writer_worker, args=(i,)) 
               for i in range(3)]
    readers = [threading.Thread(target=manager.reader_worker, args=(i,)) 
               for i in range(2)]
    
    # å¯åŠ¨å¹¶ç­‰å¾…å®Œæˆ
    for t in writers + readers:
        t.start()
    for t in writers + readers:
        t.join()
    
    print("æ‰€æœ‰å¹¶å‘æ“ä½œå®Œæˆ")
```

### 2.2 SQLiteå¹¶å‘

```python
import sqlite3
import threading
from contextlib import contextmanager

class SQLiteConcurrentManager:
    def __init__(self, db_path="concurrent_sqlite.db"):
        self.db_path = db_path
        self._init_table()
    
    def _init_table(self):
        """åˆå§‹åŒ–æ•°æ®è¡¨ï¼Œå¼€å¯WALä¼˜åŒ–å¹¶å‘"""
        with self.get_connection() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    content TEXT,
                    create_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            conn.execute("PRAGMA journal_mode=WAL")  # å¼€å¯WALæå‡å¹¶å‘
    
    @contextmanager
    def get_connection(self):
        """è¿æ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç¡®ä¿å…³é—­"""
        conn = sqlite3.connect(
            self.db_path,
            check_same_thread=False,  # å…è®¸è·¨çº¿ç¨‹
            timeout=10  # é”ç­‰å¾…è¶…æ—¶
        )
        try:
            yield conn
        finally:
            conn.close()
    
    def read_data(self, worker_id):
        """å¹¶å‘è¯»æ“ä½œ"""
        with self.get_connection() as conn:
            results = conn.execute("SELECT * FROM data LIMIT 10").fetchall()
        print(f"Reader {worker_id} è¯»å– {len(results)} æ¡æ•°æ®")
        return results
    
    def write_data(self, worker_id, content):
        """å¹¶å‘å†™æ“ä½œ"""
        with self.get_connection() as conn:
            conn.execute(
                "INSERT INTO data (content) VALUES (?)",
                (f"Worker {worker_id}: {content}",)
            )
            conn.commit()  # å†™æ“ä½œéœ€æäº¤
        print(f"Writer {worker_id} å†™å…¥å®Œæˆ")

## ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    manager = SQLiteConcurrentManager()
    
    # çº¿ç¨‹æ‰§è¡Œå‡½æ•°
    def read_worker(worker_id):
        manager.read_data(worker_id)
    
    def write_worker(worker_id):
        for i in range(50):
            manager.write_data(worker_id, f"Test data {i}")
    
    # 2ä¸ªè¯»çº¿ç¨‹ã€2ä¸ªå†™çº¿ç¨‹
    readers = [threading.Thread(target=read_worker, args=(i,)) for i in range(2)]
    writers = [threading.Thread(target=write_worker, args=(i,)) for i in range(2)]
    
    # å¯åŠ¨å¹¶ç­‰å¾…å®Œæˆ
    for t in readers + writers:
        t.start()
    for t in readers + writers:
        t.join()
    
    print("æ‰€æœ‰SQLiteå¹¶å‘æ“ä½œå®Œæˆ")
```

### 2.3 Rediså¹¶å‘

```python
import redis
from concurrent.futures import ThreadPoolExecutor

class RedisConcurrentManager:
    def __init__(self, host='localhost', port=6379, db=0):
        """åˆå§‹åŒ–Redisè¿æ¥æ± ï¼Œä¼˜åŒ–å¹¶å‘"""
        self.pool = redis.ConnectionPool(
            host=host, port=port, db=db,
            max_connections=20,  # æ§åˆ¶æœ€å¤§è¿æ¥æ•°
            decode_responses=True  # è‡ªåŠ¨è§£ç å­—ç¬¦ä¸²
        )
    
    def get_client(self):
        """ä»è¿æ¥æ± è·å–å®¢æˆ·ç«¯"""
        return redis.Redis(connection_pool=self.pool)
    
    def batch_get(self, worker_id, keys):
        """æ‰¹é‡è¯»ï¼špipelineæå‡æ•ˆç‡"""
        client = self.get_client()
        pipe = client.pipeline(transaction=False)
        for key in keys:
            pipe.get(key)
        results = pipe.execute()
        print(f"Worker {worker_id} è¯»å– {len(keys)} ä¸ªé”®ï¼ŒæˆåŠŸ {sum(1 for r in results if r)} ä¸ª")
        return results
    
    def batch_set(self, worker_id, key_value_pairs):
        """æ‰¹é‡å†™ï¼špipelineå‡å°‘å¼€é”€"""
        client = self.get_client()
        pipe = client.pipeline(transaction=False)
        for key, value in key_value_pairs:
            pipe.set(key, value, ex=3600)  # 1å°æ—¶è¿‡æœŸ
        pipe.execute()
        print(f"Worker {worker_id} å†™å…¥ {len(key_value_pairs)} ä¸ªé”®å€¼å¯¹")

## ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    manager = RedisConcurrentManager()
    
    # æµ‹è¯•æ•°æ®ï¼š300ä¸ªé”®å€¼å¯¹ï¼Œåˆ†3æ‰¹
    test_data = [(f"key_{i}", f"value_{i}") for i in range(300)]
    batch_size = 100
    write_batches = [test_data[i:i+batch_size] for i in range(0, 300, batch_size)]
    read_batches = [[f"key_{i}" for i in range(j*100, (j+1)*100)] for j in range(3)]
    
    # çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=3) as executor:
        write_futures = [executor.submit(manager.batch_set, idx, batch) 
                        for idx, batch in enumerate(write_batches)]
        read_futures = [executor.submit(manager.batch_get, idx, batch) 
                       for idx, batch in enumerate(read_batches)]
    
    # ç­‰å¾…å®Œæˆ
    for future in write_futures + read_futures:
        future.result()
    
    print("æ‰€æœ‰Rediså¹¶å‘æ“ä½œå®Œæˆ")
```



<br/>



## âœ… ä¸‰ã€æœ€ä½³å®è·µ

### 3.1 è¿æ¥ç®¡ç†

- **ä¼˜å…ˆè¿æ¥æ± **ï¼šé«˜é¢‘è®¿é—®ç”¨è¿æ¥æ± å‡å¼€é”€ã€æ§è¿æ¥æ•°ï¼›Redis å¿…ç”¨ï¼ŒDuckDB/SQLite é«˜é¢‘å»ºè®®ç”¨ã€‚
- **åŠæ—¶é‡Šæ”¾è¿æ¥**ï¼šç”¨ with è¯­å¥ä¿è¯è‡ªåŠ¨å…³é—­ï¼Œé¿å…æ³„éœ²ã€‚
- **åˆç†è®¾å‚æ•°**ï¼šSQLite è®¾ timeout é˜²é”è¶…æ—¶ï¼ŒRedis è°ƒ max_connections é€‚é…ä¸šåŠ¡ã€‚

### 3.2 æ€§èƒ½ä¼˜åŒ–

- **æ‰¹é‡æ“ä½œä¼˜å…ˆ**ï¼šRedis ç”¨ pipelineï¼ŒDuckDB/SQLite ç”¨æ‰¹é‡ SQLï¼Œå‡å¼€é”€ã€‚
- **é€‚é…è¯»å†™ç‰¹æ€§**ï¼šDuckDB é€‚é…è¯»å¤šå†™å°‘ï¼›SQLite æ§å†™å¹¶å‘ï¼›Redis é¿é•¿è€—æ—¶å‘½ä»¤é˜»å¡ã€‚
- **å¼€å¯ä¼˜åŒ–æ¨¡å¼**ï¼šSQLite å¼€ WAL æå¹¶å‘ï¼›Redis éå¿…è¦ä¸å¯ç”¨äº‹åŠ¡ã€‚

### 3.3 å¸¸è§é™·é˜±

| å¸¸è§é™·é˜±         | è§„é¿æ–¹æ¡ˆ                                                     |
| ---------------- | ------------------------------------------------------------ |
| SQLite å†™æ­»é”    | å¼€ WAL æ¨¡å¼ï¼›è®¾åˆç† timeoutï¼›é¿å…é•¿æŒå†™è¿æ¥ä¸æäº¤ã€‚          |
| è¿æ¥æ³„éœ²         | å¼ºåˆ¶ç”¨ with è¯­å¥ï¼›å¼‚å¸¸æ—¶ä¿éšœå…³è¿æ¥ï¼›å®šæœŸç›‘æ§è¿æ¥æ•°ã€‚         |
| Redis å•çº¿ç¨‹é˜»å¡ | é¿ KEYS ç­‰é•¿è€—æ—¶å‘½ä»¤ï¼›æ‰¹é‡æ›¿ä»£å¾ªç¯å•æ¡ï¼›æ‹†åˆ†å¤§é”®ã€‚           |
| è¿‡åº¦å¹¶å‘         | æŒ‰ç¡¬ä»¶å’Œæ•°æ®åº“ç‰¹æ€§è®¾å¹¶å‘åº¦ï¼ˆSQLite å†™å¹¶å‘â‰¤2-3ï¼›Redis ä¸è¶…è¿æ¥æ± ä¸Šé™ï¼‰ã€‚ |



<br/>



## ğŸ” å››ã€å¹¶å‘æ·±åº¦è§£æ

### 4.1 DuckDBè§£æ

DuckDB å¹¶å‘æ ¸å¿ƒï¼šå•çº¿ç¨‹æ‰§è¡Œ + å¤šè¿æ¥éš”ç¦» + MVCCã€‚

- å•çº¿ç¨‹æŸ¥è¯¢å¼•æ“ï¼Œä¸­å¤®è°ƒåº¦å™¨ä¿éšœåŸå­æ€§ä¸ä¸€è‡´æ€§ã€‚
- MVCC ç»´æŠ¤ç‹¬ç«‹æ•°æ®ç‰ˆæœ¬ï¼Œå®ç°è¯»å†™ä¸é˜»å¡ã€‚
- å†…éƒ¨ç»†ç²’åº¦é”åè°ƒèµ„æºï¼Œç”¨æˆ·æ— æ„ŸçŸ¥ã€‚
- æ”¯æŒ ACID äº‹åŠ¡ï¼Œå¹¶å‘äº‹åŠ¡é  MVCC éš”ç¦»ã€é”ä¿éšœä¸€è‡´ã€‚

### 4.2 SQLiteè§£æ

SQLite å¹¶å‘æ ¸å¿ƒï¼šæ–‡ä»¶çº§é”ï¼ŒWAL æ¨¡å¼æ˜¯å¹¶å‘æå‡å…³é”®ã€‚

- å››çº§é”ï¼šå…±äº«ï¼ˆè¯»ï¼‰ã€é¢„ç•™ã€æœªå†³ã€ç‹¬å ï¼ˆå†™ï¼‰ï¼Œå†™éœ€å‡çº§ç‹¬å é”ã€‚
- WAL æ¨¡å¼ï¼šå†™å˜æ›´å…¥æ—¥å¿—ï¼Œä¸è¦†ç›–åŸæ•°æ®ï¼Œå®ç°è¯»å†™å¹¶å‘ï¼›æ—¥å¿—å®šæœŸåˆå¹¶ã€‚
- å†™äº‹åŠ¡äº’æ–¥ï¼Œè¯»äº‹åŠ¡å¹¶å‘ä¾èµ–é”ä¸ WAL æ¨¡å¼ã€‚

### 4.3 Redisè§£æ

Redis å¹¶å‘æ ¸å¿ƒï¼šå•çº¿ç¨‹äº‹ä»¶å¾ªç¯ + I/O å¤šè·¯å¤ç”¨ï¼Œæ— éœ€ä¼ ç»Ÿé”ã€‚

- å•çº¿ç¨‹æ‰§è¡Œå‘½ä»¤ï¼Œå¤©ç„¶è§„é¿å¹¶å‘ç«äº‰ã€‚
- I/O å¤šè·¯å¤ç”¨å¤„ç†å¤šè¿æ¥ï¼Œå®ç°å•çº¿ç¨‹å¹¶å‘ã€‚
- å‘½ä»¤æŒ‰æ¥æ”¶é¡ºåº FIFO æ‰§è¡Œï¼Œä¿éšœæœ‰åºã€‚
- MULTI/EXEC å®ç°äº‹åŠ¡ï¼Œæ‰¹é‡æ‰§è¡Œä¸ä¸­æ–­ï¼Œå¼±ä¸€è‡´æ€§æ— å›æ»šã€‚



<br/>



## ğŸ’¡ äº”ã€åœºæ™¯å»ºè®®

æŒ‰ä¸šåŠ¡åœºæ™¯é€‰æ‹©åµŒå…¥å¼æ•°æ®åº“åŠå¹¶å‘ç­–ç•¥ï¼š

### 5.1 DuckDB çš„åœºæ™¯

- åˆ†æå‹åœºæ™¯ï¼šæ•°æ®ä»“åº“ã€æŠ¥è¡¨ç»Ÿè®¡ç­‰è¯»å¤šå†™å°‘åœºæ™¯ã€‚
- å•èŠ‚ç‚¹é«˜æ€§èƒ½ï¼šéœ€å•çº¿ç¨‹é«˜æ•ˆæ€§ï¼ŒåŒæ—¶æ”¯æŒå¤šè¿æ¥å¹¶å‘æŸ¥è¯¢ã€‚
- SQL å…¼å®¹ï¼šéœ€å®Œæ•´ SQL è¯­æ³•åŠå¤æ‚æŸ¥è¯¢èƒ½åŠ›ã€‚

### 5.2 SQLite çš„åœºæ™¯

- åµŒå…¥å¼åº”ç”¨ï¼šç§»åŠ¨ç«¯ã€æ¡Œé¢ç«¯ã€ç‰©è”ç½‘ç­‰è½»é‡å­˜å‚¨ã€‚
- ä½å¹¶å‘å†™ï¼šå†™å°‘è¯»å¤šï¼Œå¯¹èµ„æºå ç”¨è¦æ±‚ä¸¥æ ¼ã€‚
- å•æœºæœ¬åœ°å­˜å‚¨ï¼šæ— ç½‘ç»œä¾èµ–ï¼Œæ•°æ®ç‹¬ç«‹æ€§è¦æ±‚é«˜ã€‚

### 5.3 Redis çš„åœºæ™¯

- ç¼“å­˜åœºæ™¯ï¼šçƒ­ç‚¹æ•°æ®ã€ä¼šè¯å­˜å‚¨ã€è®¡æ•°å™¨ç­‰é«˜é¢‘è¯»å†™ã€‚
- å®æ—¶å¤„ç†ï¼šæ¶ˆæ¯é˜Ÿåˆ—ã€æ’è¡Œæ¦œç­‰éœ€é«˜å¹¶å‘å“åº”ã€‚
- åˆ†å¸ƒå¼åœºæ™¯ï¼šéœ€é›†ç¾¤ã€é«˜å¯ç”¨ï¼ˆä¸»ä»/å“¨å…µï¼‰æ”¯æŒã€‚

# TiDB æ•°æ®åº“æŒ‡å—

[TOC]



## ğŸŒŸ ä¸€. TiDB ä»‹ç»

**[TiDB](https://github.com/pingcap/tidb)** æ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼ NewSQL æ•°æ®åº“ï¼Œå…¼å®¹ MySQL åè®®ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•ã€å¼ºä¸€è‡´æ€§å’Œé«˜å¯ç”¨æ€§ã€‚å®ƒç»“åˆäº†ä¼ ç»Ÿ RDBMS çš„ ACID ç‰¹æ€§å’Œ NoSQL çš„å¯æ‰©å±•æ€§ã€‚

**æ ¸å¿ƒä¼˜åŠ¿ï¼š**

- ğŸ”„ **æ°´å¹³æ‰©å±•**ï¼šè®¡ç®—å±‚å’Œå­˜å‚¨å±‚å‡å¯ç‹¬ç«‹æ‰©å±•ï¼Œæ”¯æŒ PB çº§æ•°æ®å¤„ç†
- ğŸ”— **MySQL å…¼å®¹**ï¼šå®Œå…¨å…¼å®¹ MySQL 5.7/8.0 åè®®ï¼Œè¿ç§»æˆæœ¬ä½
- ğŸ“Š **HTAP æ¶æ„**ï¼šåŒæ—¶æ”¯æŒ OLTPï¼ˆåœ¨çº¿äº‹åŠ¡å¤„ç†ï¼‰å’Œ OLAPï¼ˆåœ¨çº¿åˆ†æå¤„ç†ï¼‰
- ğŸ›¡ï¸ **å¼ºä¸€è‡´æ€§**ï¼šåŸºäº Raft åè®®å®ç°åˆ†å¸ƒå¼äº‹åŠ¡å’Œæ•°æ®ä¸€è‡´æ€§
- âš¡ï¸ **é«˜å¯ç”¨æ€§**ï¼šè‡ªåŠ¨æ•…éšœè½¬ç§»ï¼Œæ— å•ç‚¹æ•…éšœ
- ğŸŒ **äº‘åŸç”Ÿ**ï¼šæ”¯æŒ Kubernetes éƒ¨ç½²ï¼Œé€‚åˆäº‘ç¯å¢ƒ



<br/>



## âš™ï¸ äºŒ. å®‰è£…ä¸é…ç½®

### 2.1 æœ¬åœ°å¼€å‘ç¯å¢ƒå®‰è£…

**ä½¿ç”¨ Dockerï¼ˆæ¨èï¼‰**

```bash
# æ‹‰å–æœ€æ–°ç‰ˆæœ¬é•œåƒ
docker pull pingcap/tidb:v7.5.0

# å¯åŠ¨ TiDB Playgroundï¼ˆåŒ…å« PDã€TiKVã€TiDBï¼‰
docker run --name tidb-server -p 4000:4000 -p 10080:10080 pingcap/tidb:v7.5.0

# æˆ–è€…ä½¿ç”¨ docker-compose
wget https://raw.githubusercontent.com/pingcap/tidb-docker-compose/master/docker-compose.yml
docker-compose up -d
```

**ä½¿ç”¨ Homebrewï¼ˆmacOSï¼‰**

```bash
# å®‰è£… TiUPï¼ˆTiDB å®˜æ–¹åŒ…ç®¡ç†å™¨ï¼‰
brew install tispark/tispark/tiup

# å¯åŠ¨æœ¬åœ°æµ‹è¯•é›†ç¾¤
tiup playground

# å¯åŠ¨æŒ‡å®šç‰ˆæœ¬
tiup playground v7.5.0
```

### 2.2 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

**ä½¿ç”¨ TiUP éƒ¨ç½²é›†ç¾¤**

```bash
# å®‰è£… TiUP
curl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh

# ç¼–è¾‘æ‹“æ‰‘é…ç½®æ–‡ä»¶
cat > topology.yaml << EOF
# å…¨å±€é…ç½®
global:
  user: "tidb"
  ssh_port: 22
  deploy_dir: "/tidb-deploy"
  data_dir: "/tidb-data"

# PD Server é…ç½®
pd_servers:
  - host: 10.0.1.1
  - host: 10.0.1.2
  - host: 10.0.1.3

# TiDB Server é…ç½®
tidb_servers:
  - host: 10.0.1.4
  - host: 10.0.1.5

# TiKV Server é…ç½®
tikv_servers:
  - host: 10.0.1.6
  - host: 10.0.1.7
  - host: 10.0.1.8
EOF

# éƒ¨ç½²é›†ç¾¤
tiup cluster deploy my-cluster v7.5.0 ./topology.yaml --user root -p

# å¯åŠ¨é›†ç¾¤
tiup cluster start my-cluster
```

### 2.3 è¿æ¥æµ‹è¯•

```bash
# ä½¿ç”¨ MySQL å®¢æˆ·ç«¯è¿æ¥
mysql -h 127.0.0.1 -P 4000 -u root -p

# æˆ–è€…ä½¿ç”¨å®˜æ–¹å®¢æˆ·ç«¯
tiup client
```

### 2.4 æ•°æ®åº“å®¢æˆ·ç«¯

- æ¨èä½¿ç”¨ **DBeaver** æˆ– **Navicat**
- VSCode æ’ä»¶ï¼š**MySQL**
- å‘½ä»¤è¡Œå·¥å…·ï¼š**mycli**ï¼ˆå¢å¼ºç‰ˆ MySQL å®¢æˆ·ç«¯ï¼‰



<br/>



## ğŸ“™ ä¸‰. åŸºç¡€æ“ä½œ

### 3.1 æ•°æ®åº“è¿æ¥

```python
import pymysql

# å»ºç«‹è¿æ¥
connection = pymysql.connect(
    host='127.0.0.1',
    port=4000,
    user='root',
    password='',
    database='test',
    charset='utf8mb4'
)

cursor = connection.cursor()
```

### 3.2 åŸºæœ¬æ“ä½œ

**åˆ›å»ºæ•°æ®åº“å’Œè¡¨**

```sql
-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE IF NOT EXISTS ecommerce;
USE ecommerce;

-- åˆ›å»ºç”¨æˆ·è¡¨
CREATE TABLE users (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- åˆ›å»ºè®¢å•è¡¨
CREATE TABLE orders (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    order_number VARCHAR(50) UNIQUE NOT NULL,
    total_amount DECIMAL(10,2) NOT NULL,
    status ENUM('pending', 'paid', 'shipped', 'delivered', 'cancelled') DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);
```

**æ’å…¥æ•°æ®**

```sql
-- æ’å…¥ç”¨æˆ·æ•°æ®
INSERT INTO users (username, email, password_hash) VALUES 
('john_doe', 'john@example.com', 'hashed_password_1'),
('jane_smith', 'jane@example.com', 'hashed_password_2');

-- æ’å…¥è®¢å•æ•°æ®
INSERT INTO orders (user_id, order_number, total_amount, status) VALUES 
(1, 'ORD001', 299.99, 'paid'),
(2, 'ORD002', 159.50, 'pending');
```

### 3.3 æŸ¥è¯¢æ“ä½œ

**åŸºç¡€æŸ¥è¯¢**

```sql
-- ç®€å•æŸ¥è¯¢
SELECT username, email FROM users WHERE id = 1;

-- è¿æ¥æŸ¥è¯¢
SELECT u.username, o.order_number, o.total_amount, o.status
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE o.status = 'paid'
ORDER BY o.created_at DESC;

-- èšåˆæŸ¥è¯¢
SELECT 
    u.username,
    COUNT(o.id) as order_count,
    SUM(o.total_amount) as total_spent
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
GROUP BY u.id, u.username
HAVING order_count > 0
ORDER BY total_spent DESC;
```

**åˆ†é¡µæŸ¥è¯¢**

```sql
-- åˆ†é¡µè·å–è®¢å•åˆ—è¡¨
SELECT * FROM orders 
ORDER BY created_at DESC 
LIMIT 10 OFFSET 20;

-- è·å–æ€»æ•°
SELECT COUNT(*) as total_orders FROM orders;
```

### 3.4 äº‹åŠ¡æ“ä½œ

```python
try:
    # å¼€å§‹äº‹åŠ¡
    connection.begin()
    
    # åˆ›å»ºæ–°è®¢å•
    cursor.execute("""
        INSERT INTO orders (user_id, order_number, total_amount, status) 
        VALUES (%s, %s, %s, %s)
    """, (user_id, order_number, total_amount, 'pending'))
    
    # æ›´æ–°åº“å­˜
    cursor.execute("""
        UPDATE products 
        SET stock_quantity = stock_quantity - %s 
        WHERE id = %s AND stock_quantity >= %s
    """, (quantity, product_id, quantity))
    
    # æ£€æŸ¥æ›´æ–°å½±å“çš„è¡Œæ•°
    if cursor.rowcount == 0:
        raise Exception("åº“å­˜ä¸è¶³")
    
    # æäº¤äº‹åŠ¡
    connection.commit()
    print("è®¢å•åˆ›å»ºæˆåŠŸï¼")
    
except Exception as e:
    # å›æ»šäº‹åŠ¡
    connection.rollback()
    print(f"äº‹åŠ¡å¤±è´¥ï¼Œå·²å›æ»š: {e}")
finally:
    cursor.close()
    connection.close()
```



<br/>



## ğŸš€ å››. é«˜çº§ç‰¹æ€§

### 4.1 åˆ†å¸ƒå¼äº‹åŠ¡

**ä¹è§‚äº‹åŠ¡ vs æ‚²è§‚äº‹åŠ¡**

```sql
-- è®¾ç½®ä¼šè¯çº§åˆ«çš„äº‹åŠ¡æ¨¡å¼

-- ä¹è§‚äº‹åŠ¡ï¼ˆé»˜è®¤ï¼‰
SET SESSION tidb_txn_mode = 'optimistic';

-- æ‚²è§‚äº‹åŠ¡
SET SESSION tidb_txn_mode = 'pessimistic';

-- ç¤ºä¾‹ï¼šæ‚²è§‚äº‹åŠ¡å¤„ç†é«˜å¹¶å‘åœºæ™¯
START TRANSACTION;
SELECT * FROM accounts WHERE id = 1 FOR UPDATE;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
COMMIT;
```

**å¤§äº‹åŠ¡ä¼˜åŒ–**

```python
# æ‰¹é‡å¤„ç†å¤§é‡æ•°æ®
def batch_process_large_data(connection, data_list, batch_size=1000):
    cursor = connection.cursor()
    
    try:
        connection.begin()
        
        for i in range(0, len(data_list), batch_size):
            batch = data_list[i:i + batch_size]
            
            # æ‰¹é‡æ’å…¥
            sql = """
                INSERT INTO large_table (col1, col2, col3) 
                VALUES (%s, %s, %s)
            """
            cursor.executemany(sql, batch)
            
            # å®šæœŸæäº¤é¿å…äº‹åŠ¡è¿‡å¤§
            if i % (batch_size * 10) == 0:
                connection.commit()
                connection.begin()
        
        connection.commit()
        
    except Exception as e:
        connection.rollback()
        raise e
    finally:
        cursor.close()
```

### 4.2 HTAP æ··åˆè´Ÿè½½

**å®æ—¶åˆ†ææŸ¥è¯¢**

```sql
-- åœ¨çº¿äº‹åŠ¡å¤„ç†ï¼ˆOLTPï¼‰
INSERT INTO user_behavior (user_id, action, timestamp) VALUES (123, 'click', NOW());
UPDATE user_profiles SET last_active = NOW() WHERE user_id = 123;

-- å®æ—¶åˆ†æå¤„ç†ï¼ˆOLAPï¼‰
SELECT 
    DATE(timestamp) as date,
    action,
    COUNT(*) as count,
    COUNT(DISTINCT user_id) as unique_users
FROM user_behavior 
WHERE timestamp >= DATE_SUB(NOW(), INTERVAL 7 DAY)
GROUP BY DATE(timestamp), action
ORDER BY date DESC, count DESC;
```

**TiFlash åˆ—å¼å­˜å‚¨åŠ é€Ÿåˆ†æ**

```sql
-- ä¸ºè¡¨å¯ç”¨ TiFlash å‰¯æœ¬
ALTER TABLE orders SET TIFLASH REPLICA 1;

-- å¼ºåˆ¶ä½¿ç”¨ TiFlash è¿›è¡Œåˆ†ææŸ¥è¯¢
SELECT /*+ READ_FROM_STORAGE(TIFLASH[orders]) */ 
    user_id,
    COUNT(*) as order_count,
    AVG(total_amount) as avg_order_value
FROM orders 
WHERE created_at >= DATE_SUB(NOW(), INTERVAL 30 DAY)
GROUP BY user_id
ORDER BY order_count DESC
LIMIT 100;
```

### 4.3 åˆ†åŒºè¡¨

```sql
-- æŒ‰æ—¶é—´èŒƒå›´åˆ†åŒº
CREATE TABLE sales_data (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT,
    amount DECIMAL(10,2),
    sale_date DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (YEAR(sale_date)) (
    PARTITION p2022 VALUES LESS THAN (2023),
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);

-- æŒ‰å“ˆå¸Œåˆ†åŒºåˆ†æ•£çƒ­ç‚¹
CREATE TABLE user_sessions (
    session_id VARCHAR(64) PRIMARY KEY,
    user_id BIGINT,
    ip_address VARCHAR(45),
    created_at TIMESTAMP
) PARTITION BY HASH(user_id) PARTITIONS 16;

-- æŸ¥è¯¢ç‰¹å®šåˆ†åŒº
SELECT * FROM sales_data PARTITION (p2023) WHERE amount > 1000;
```

### 4.4 ç´¢å¼•ä¼˜åŒ–

```sql
-- åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_user_status_created 
ON orders (user_id, status, created_at);

-- åˆ›å»ºå‰ç¼€ç´¢å¼•ï¼ˆèŠ‚çœç©ºé—´ï¼‰
CREATE INDEX idx_email_prefix ON users (email(20));

-- æŸ¥çœ‹ç´¢å¼•ä½¿ç”¨æƒ…å†µ
EXPLAIN SELECT * FROM orders WHERE user_id = 123 AND status = 'paid';

-- åˆ é™¤æœªä½¿ç”¨çš„ç´¢å¼•
DROP INDEX idx_unused ON orders;
```



<br/>



## ğŸ› ï¸ äº”. åº”ç”¨æ¡ˆä¾‹

### 5.1 ç”µå•†å¹³å°æ•°æ®å¤„ç†

**é¡¹ç›®ç»“æ„**

```shell
e-commerce-platform/
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ init.sql              # æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
â”‚   â”œâ”€â”€ migrations/           # æ•°æ®åº“è¿ç§»æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ 001_create_tables.sql
â”‚   â”‚   â””â”€â”€ 002_add_indexes.sql
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ order.py
â”‚   â”‚   â””â”€â”€ product.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ order_service.py
â”‚   â”‚   â””â”€â”€ analytics_service.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ db_connection.py
â””â”€â”€ config/
    â””â”€â”€ database.yaml
```

**æ ¸å¿ƒæœåŠ¡å®ç°**

```python
# db_connection.py
import pymysql
from contextlib import contextmanager

class DatabaseManager:
    def __init__(self, config):
        self.config = config
    
    @contextmanager
    def get_connection(self):
        connection = pymysql.connect(**self.config)
        try:
            yield connection
        finally:
            connection.close()

# order_service.py
class OrderService:
    def __init__(self, db_manager):
        self.db = db_manager
    
    def create_order(self, user_id, items):
        with self.db.get_connection() as conn:
            try:
                conn.begin()
                
                # è®¡ç®—æ€»é‡‘é¢
                total_amount = sum(item['price'] * item['quantity'] for item in items)
                
                # åˆ›å»ºè®¢å•
                with conn.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO orders (user_id, total_amount, status) 
                        VALUES (%s, %s, 'pending')
                    """, (user_id, total_amount))
                    
                    order_id = cursor.lastrowid
                    
                    # åˆ›å»ºè®¢å•é¡¹
                    for item in items:
                        cursor.execute("""
                            INSERT INTO order_items (order_id, product_id, quantity, price)
                            VALUES (%s, %s, %s, %s)
                        """, (order_id, item['product_id'], item['quantity'], item['price']))
                
                conn.commit()
                return order_id
                
            except Exception as e:
                conn.rollback()
                raise e
```

### 5.2 å®æ—¶æ•°æ®åˆ†æ

```python
# analytics_service.py
class AnalyticsService:
    def __init__(self, db_manager):
        self.db = db_manager
    
    def get_sales_report(self, start_date, end_date):
        """è·å–é”€å”®æŠ¥è¡¨"""
        query = """
            SELECT 
                DATE(created_at) as date,
                COUNT(*) as order_count,
                SUM(total_amount) as daily_revenue,
                AVG(total_amount) as avg_order_value
            FROM orders 
            WHERE created_at BETWEEN %s AND %s
                AND status IN ('paid', 'delivered')
            GROUP BY DATE(created_at)
            ORDER BY date
        """
        
        with self.db.get_connection() as conn:
            with conn.cursor(pymysql.cursors.DictCursor) as cursor:
                cursor.execute(query, (start_date, end_date))
                return cursor.fetchall()
    
    def get_top_products(self, limit=10):
        """è·å–çƒ­é”€å•†å“"""
        query = """
            SELECT 
                p.name,
                p.category,
                SUM(oi.quantity) as total_sold,
                SUM(oi.quantity * oi.price) as revenue
            FROM order_items oi
            JOIN products p ON oi.product_id = p.id
            JOIN orders o ON oi.order_id = o.id
            WHERE o.created_at >= DATE_SUB(NOW(), INTERVAL 30 DAY)
                AND o.status IN ('paid', 'delivered')
            GROUP BY p.id, p.name, p.category
            ORDER BY total_sold DESC
            LIMIT %s
        """
        
        with self.db.get_connection() as conn:
            with conn.cursor(pymysql.cursors.DictCursor) as cursor:
                cursor.execute(query, (limit,))
                return cursor.fetchall()
```

### 5.3 ç›‘æ§ä¸è¿ç»´

```python
# monitoring.py
class TiDBMonitor:
    def __init__(self, db_config):
        self.db_config = db_config
    
    def get_cluster_status(self):
        """è·å–é›†ç¾¤çŠ¶æ€ä¿¡æ¯"""
        queries = {
            'pd_members': "SHOW PD REGIONS",
            'tikv_stores': "SHOW STORES",
            'tidb_servers': "SHOW SERVERS",
            'schema_info': "SELECT table_schema, table_name, table_rows FROM information_schema.tables WHERE table_schema NOT IN ('INFORMATION_SCHEMA', 'PERFORMANCE_SCHEMA', 'mysql')"
        }
        
        results = {}
        with pymysql.connect(**self.db_config) as conn:
            with conn.cursor(pymysql.cursors.DictCursor) as cursor:
                for name, query in queries.items():
                    try:
                        cursor.execute(query)
                        results[name] = cursor.fetchall()
                    except Exception as e:
                        results[name] = f"Error: {str(e)}"
        
        return results
    
    def get_performance_metrics(self):
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        query = """
            SELECT 
                VARIABLE_NAME,
                VARIABLE_VALUE
            FROM performance_schema.global_status 
            WHERE VARIABLE_NAME IN (
                'Threads_connected',
                'Threads_running',
                'Queries',
                'Slow_queries',
                'Created_tmp_disk_tables',
                'Handler_read_rnd_next'
            )
        """
        
        with pymysql.connect(**self.db_config) as conn:
            with conn.cursor(pymysql.cursors.DictCursor) as cursor:
                cursor.execute(query)
                return dict((row['VARIABLE_NAME'], row['VARIABLE_VALUE']) for row in cursor.fetchall())
```



<br/>



## ğŸ† å…­. æ€§èƒ½ä¼˜åŒ–

### 6.1 è¯»å†™ä¼˜åŒ–

**æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥**

```sql
-- ä½¿ç”¨è¦†ç›–ç´¢å¼•é¿å…å›è¡¨
SELECT user_id, status, created_at 
FROM orders 
WHERE user_id = 123 AND status = 'paid';

-- é¿å… SELECT *
SELECT id, username, email FROM users WHERE active = 1;

-- åˆç†ä½¿ç”¨ LIMIT
SELECT * FROM orders ORDER BY created_at DESC LIMIT 100;

-- ä½¿ç”¨ EXISTS æ›¿ä»£ INï¼ˆå­æŸ¥è¯¢ï¼‰
SELECT * FROM users u 
WHERE EXISTS (SELECT 1 FROM orders o WHERE o.user_id = u.id AND o.status = 'paid');
```

**æ‰¹é‡æ“ä½œä¼˜åŒ–**

```python
# æ‰¹é‡æ’å…¥ä¼˜åŒ–
def batch_insert_optimized(cursor, table, columns, data, batch_size=1000):
    placeholders = ','.join(['%s'] * len(columns))
    columns_str = ','.join(columns)
    
    sql = f"INSERT INTO {table} ({columns_str}) VALUES ({placeholders})"
    
    for i in range(0, len(data), batch_size):
        batch = data[i:i + batch_size]
        cursor.executemany(sql, batch)

# æ‰¹é‡æ›´æ–°ä¼˜åŒ–
def batch_update_optimized(cursor, table, updates, conditions, batch_size=100):
    for i in range(0, len(updates), batch_size):
        batch_updates = updates[i:i + batch_size]
        batch_conditions = conditions[i:i + batch_size]
        
        # æ„å»ºæ‰¹é‡æ›´æ–°è¯­å¥
        case_statements = []
        where_values = []
        
        for update_dict, condition_dict in zip(batch_updates, batch_conditions):
            for column, value in update_dict.items():
                case_statements.append(f"{column} = CASE id ")
                # æ·»åŠ å…·ä½“çš„ CASE æ¡ä»¶
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
```

### 6.2 å­˜å‚¨ä¼˜åŒ–

**è¡¨ç»“æ„è®¾è®¡**

```sql
-- é€‰æ‹©åˆé€‚çš„æ•°æ®ç±»å‹
CREATE TABLE optimized_table (
    id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
    small_enum TINYINT UNSIGNED,  -- æ›¿ä»£ ENUM
    flag BOOLEAN,                 -- æ›¿ä»£ TINYINT(1)
    score DECIMAL(5,2),           -- ç²¾ç¡®çš„å°æ•°
    description VARCHAR(255),     -- é¿å… TEXTï¼ˆå¦‚æœé•¿åº¦å¯æ§ï¼‰
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_created_flag (created_at, flag)
) ENGINE=InnoDB;

-- å½’æ¡£å†å²æ•°æ®
CREATE TABLE orders_archive LIKE orders;

INSERT INTO orders_archive 
SELECT * FROM orders 
WHERE created_at < DATE_SUB(NOW(), INTERVAL 1 YEAR);

DELETE FROM orders 
WHERE created_at < DATE_SUB(NOW(), INTERVAL 1 YEAR);
```

### 6.3 åˆ†å¸ƒå¼ä¼˜åŒ–

**Region åˆ†è£‚æ§åˆ¶**

```sql
-- æŸ¥çœ‹è¡¨çš„ Region åˆ†å¸ƒ
SHOW TABLE orders REGIONS;

-- æ‰‹åŠ¨åˆ†è£‚ Regionï¼ˆè§£å†³çƒ­ç‚¹é—®é¢˜ï¼‰
SPLIT TABLE orders BETWEEN (1) AND (1000000) REGIONS 16;

-- è®¾ç½®åˆé€‚çš„ Region å¤§å°
SET CONFIG tikv raftstore.region-split-size = '96MB';
```

**è´Ÿè½½å‡è¡¡**

```bash
# ä½¿ç”¨ pd-ctl æŸ¥çœ‹å’Œè°ƒæ•´è°ƒåº¦
./pd-ctl -u http://pd_addr:2379

# æŸ¥çœ‹ store çŠ¶æ€
>> store

# å¹³è¡¡ leader
>> scheduler add balance-leader-scheduler

# å¹³è¡¡ region
>> scheduler add balance-region-scheduler
```

### 6.4 ç›‘æ§å‘Šè­¦

```yaml
# Prometheus ç›‘æ§é…ç½®ç¤ºä¾‹
- job_name: 'tidb-cluster'
  static_configs:
  - targets: ['tidb-0:10080', 'tidb-1:10080']
  - targets: ['tikv-0:20180', 'tikv-1:20180', 'tikv-2:20180']
  - targets: ['pd-0:2379', 'pd-1:2379', 'pd-2:2379']

# å…³é”®ç›‘æ§æŒ‡æ ‡
metrics:
  - name: tidb_server_connections
    description: å½“å‰è¿æ¥æ•°
    alert_threshold: 80% of max_connections
  
  - name: tikv_grpc_msg_duration_seconds
    description: gRPC è¯·æ±‚å»¶è¿Ÿ
    alert_threshold: > 1s
  
  - name: pd_scheduler_region_heartbeat
    description: Region å¿ƒè·³é—´éš”
    alert_threshold: > 10s
```



<br/>



## ğŸ“ ä¸ƒ. åœºæ™¯ä¸é™åˆ¶

### 7.1 é€‚åˆåœºæ™¯

- **å¤§è§„æ¨¡åœ¨çº¿æœåŠ¡**ï¼šéœ€è¦æ°´å¹³æ‰©å±•çš„ Web åº”ç”¨ã€ç§»åŠ¨åº”ç”¨åç«¯
- **æ··åˆè´Ÿè½½åº”ç”¨**ï¼šåŒæ—¶éœ€è¦ OLTP å’Œ OLAP èƒ½åŠ›çš„ä¸šåŠ¡ç³»ç»Ÿ
- **é‡‘èçº§åº”ç”¨**ï¼šéœ€è¦å¼ºä¸€è‡´æ€§å’Œé«˜å¯ç”¨æ€§çš„äº¤æ˜“ç³»ç»Ÿ
- **å¤šç§Ÿæˆ· SaaS**ï¼šéœ€è¦éš”ç¦»å’Œæ‰©å±•èƒ½åŠ›çš„è½¯ä»¶å³æœåŠ¡
- **å®æ—¶åˆ†æ**ï¼šéœ€è¦å®æ—¶å¤„ç†å’Œåˆ†æå¤§é‡æ•°æ®çš„åœºæ™¯
- **å…¨çƒåŒ–éƒ¨ç½²**ï¼šè·¨åœ°åŸŸã€å¤šæ•°æ®ä¸­å¿ƒçš„åº”ç”¨

### 7.2 ä¸é€‚åˆåœºæ™¯

- **ç®€å•å•æœºåº”ç”¨**ï¼šå°å‹é¡¹ç›®æˆ–åŸå‹å¼€å‘ï¼ŒMySQL æ›´ç®€å•
- **è¶…ä½å»¶è¿Ÿè¦æ±‚**ï¼šå¯¹å¾®ç§’çº§å»¶è¿Ÿæœ‰æè‡´è¦æ±‚çš„é«˜é¢‘äº¤æ˜“
- **å®Œå…¨æ— çŠ¶æ€åº”ç”¨**ï¼šä¸éœ€è¦æŒä¹…åŒ–å­˜å‚¨çš„çº¯è®¡ç®—æœåŠ¡
- **é¢„ç®—æåº¦å—é™**ï¼šéœ€è¦æœ€å°åŒ–ç¡¬ä»¶æˆæœ¬çš„åœºæ™¯

### 7.3 ä¸åŒç±»äº§å“å¯¹æ¯”

| ç‰¹æ€§ | TiDB | CockroachDB | Vitess |
|------|------|-------------|--------|
| MySQL å…¼å®¹æ€§ | âœ… å®Œå…¨å…¼å®¹ | âœ… é«˜åº¦å…¼å®¹ | âœ… å®Œå…¨å…¼å®¹ |
| åˆ†å¸ƒå¼äº‹åŠ¡ | âœ… å¼ºä¸€è‡´æ€§ | âœ… å¼ºä¸€è‡´æ€§ | âŒ æœ€ç»ˆä¸€è‡´æ€§ |
| HTAP èƒ½åŠ› | âœ… åŸç”Ÿæ”¯æŒ | âŒ éœ€è¦å¤–éƒ¨ç³»ç»Ÿ | âŒ OLTP ä¸ºä¸» |
| éƒ¨ç½²å¤æ‚åº¦ | â­â­â­ ä¸­ç­‰ | â­â­â­â­ è¾ƒé«˜ | â­â­ ç®€å• |
| ç¤¾åŒºæ´»è·ƒåº¦ | âœ… éå¸¸æ´»è·ƒ | âœ… æ´»è·ƒ | â­â­ ä¸€èˆ¬ |
| å•†ä¸šæ”¯æŒ | âœ… å®˜æ–¹æä¾› | âœ… å®˜æ–¹æä¾› | â­ æœ‰é™ |



<br/>



## ğŸ“š å…«. æ‰©å±•å»ºè®®

### 8.1 ç”Ÿæ€å·¥å…·

**æ•°æ®è¿ç§»å·¥å…·**

```bash
# ä½¿ç”¨ Dumpling å¯¼å‡ºæ•°æ®
tiup dumpling -h 127.0.0.1 -P 4000 -u root -t 32 -F 256MB -o /tmp/export

# ä½¿ç”¨ Lightning å¯¼å…¥æ•°æ®
tiup tidb-lightning -config lightning.toml

# å®æ—¶åŒæ­¥ MySQL åˆ° TiDB
tiup dm-master &
tiup dm-worker &
tiup dmctl start-task ./task.yaml
```

**å¤‡ä»½æ¢å¤**

```bash
# åˆ›å»ºå¤‡ä»½
tiup br backup full -s "local:///tmp/backup" --pd "pd-addr:2379"

# æ¢å¤æ•°æ®
tiup br restore full -s "local:///tmp/backup" --pd "pd-addr:2379"

# å¢é‡å¤‡ä»½
tiup br backup incremental -s "local:///tmp/incr_backup" --pd "pd-addr:2379"
```

### 8.2 æœ€ä½³å®è·µ

**å¼€å‘è§„èŒƒ**

```sql
-- 1. ç»Ÿä¸€å‘½åè§„èŒƒ
-- è¡¨åï¼šå°å†™ + ä¸‹åˆ’çº¿ï¼Œå¦‚ user_profiles
-- å­—æ®µåï¼šå°å†™ + ä¸‹åˆ’çº¿ï¼Œå¦‚ created_at
-- ç´¢å¼•åï¼šidx_è¡¨å_å­—æ®µåï¼Œå¦‚ idx_users_email

-- 2. åˆç†è®¾ç½®å­—ç¬¦é›†
CREATE TABLE users (
    id BIGINT PRIMARY KEY,
    username VARCHAR(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;

-- 3. ä½¿ç”¨åˆé€‚çš„çº¦æŸ
ALTER TABLE orders ADD CONSTRAINT chk_amount CHECK (total_amount >= 0);
```

**è¿ç»´å»ºè®®**

1. **å®šæœŸç»´æŠ¤**ï¼š
   - ç›‘æ§é›†ç¾¤å¥åº·çŠ¶æ€
   - å®šæœŸæ¸…ç†å†å²æ•°æ®
   - ä¼˜åŒ–æ…¢æŸ¥è¯¢

2. **å®¹é‡è§„åˆ’**ï¼š
   - æ ¹æ®ä¸šåŠ¡å¢é•¿é¢„æµ‹æ‰©å®¹æ—¶æœº
   - é¢„ç•™è¶³å¤Ÿçš„èµ„æºä½™é‡
   - åˆ¶å®šåº”æ€¥é¢„æ¡ˆ

3. **å®‰å…¨é…ç½®**ï¼š
   - å¯ç”¨ TLS åŠ å¯†ä¼ è¾“
   - é…ç½®é˜²ç«å¢™è§„åˆ™
   - å®šæœŸæ›´æ–°å¯†ç ç­–ç•¥

### 8.3 å­¦ä¹ èµ„æº

- ğŸ“– å®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.pingcap.com/zh/tidb/stable
- ğŸ¥ åœ¨çº¿è¯¾ç¨‹ï¼šPingCAP Academy
- ğŸ« ç¤¾åŒºè®ºå›ï¼šAskTUG
- ğŸ™ GitHubï¼šhttps://github.com/pingcap/tidb
- ğŸ“± å¾®ä¿¡å…¬ä¼—å·ï¼šPingCAP

---

> ğŸ’¡ **æç¤º**ï¼šTiDB æ˜¯ä¸€ä¸ªå¼ºå¤§çš„åˆ†å¸ƒå¼æ•°æ®åº“ï¼Œç‰¹åˆ«é€‚åˆéœ€è¦æ°´å¹³æ‰©å±•å’Œå¼ºä¸€è‡´æ€§çš„åº”ç”¨åœºæ™¯ã€‚å»ºè®®ä»å°è§„æ¨¡å¼€å§‹å°è¯•ï¼Œé€æ­¥ç†Ÿæ‚‰å…¶ç‰¹æ€§å’Œæœ€ä½³å®è·µã€‚